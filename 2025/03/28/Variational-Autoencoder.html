<!DOCTYPE html><html lang="en" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon-32x32.png"><link rel="icon" href="/img/favicon-32x32.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Peidong Chen"><meta name="keywords" content=""><meta name="description" content="说明：本文是对变分自编码器的学习总结"><meta property="og:type" content="article"><meta property="og:title" content="变分自编码器"><meta property="og:url" content="https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html"><meta property="og:site_name" content="Pd-ch&#39;s Blog"><meta property="og:description" content="说明：本文是对变分自编码器的学习总结"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://pd-ch.github.io/assets/images/vae.png"><meta property="og:image" content="https://pd-ch.github.io/assets/images/vae-algorithm.png"><meta property="article:published_time" content="2025-03-28T00:00:00.000Z"><meta property="article:modified_time" content="2025-04-13T10:09:20.594Z"><meta property="article:author" content="Peidong Chen"><meta property="article:tag" content="AI"><meta property="article:tag" content="math"><meta property="article:tag" content="VAE"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://pd-ch.github.io/assets/images/vae.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>变分自编码器 - Pd-ch&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"pd-ch.github.io",root:"/",version:"1.9.8",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:["home"]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!1},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:{measurement_id:"G-NBF661S3CF"},tencent:{sid:null,cid:null},leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},umami:{src:null,website_id:null,domains:null,start_time:"2024-01-01T00:00:00.000Z",token:null,api_server:null}},search_path:"/local-search.xml",include_content_in_search:!0});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>Fluid.ctx.dnt||Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-NBF661S3CF",function(){function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","G-NBF661S3CF")})</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><style>.markdown-body img{box-shadow:unset!important;border-radius:0!important}</style><link rel="alternate" href="/feed.xml" title="Pd-ch's Blog" type="application/atom+xml"><link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml"><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Pd-ch&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>Home</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>Archives</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>Tags</span></a></li><li class="nav-item"><a class="nav-link" href="/links/" target="_self"><i class="iconfont icon-link-fill"></i> <span>Links</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>About</span></a></li><li class="nav-item"><a class="nav-link" href="/feed.xml" target="_self"><i class="iconfont icon-rss"></i> <span>Feed</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.4)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">变分自编码器</span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2025-03-28 00:00" pubdate>March 28, 2025</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.8k words </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 40 mins </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> views</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">变分自编码器</h1><p id="updated-time" class="note note-info">Last updated on April 13, 2025</p><div class="markdown-body"><h6 id="说明本文是对变分自编码器的学习总结">说明：本文是对变分自编码器的学习总结</h6><span id="more"></span><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.6114">🔗</a></p><h2 id="当我们谈论-vae-时我们在谈论什么">1. 当我们谈论 VAE 时，我们在谈论什么？</h2><p>变分自编码器（Variational Autoencoder，VAE）是一种生成模型，它通过学习数据的潜在表示来生成新的数据样本。VAE 的主要目标是找到一个潜在变量的分布，使得原始数据可以被表示为这个分布的概率分布。</p><p><img src="/assets/images/vae.png" srcset="/img/loading.gif" lazyload></p><p>通常的 VAE 模型包括一个编码器（Encoder）和一个解码器（Decoder）。而在无监督方法中，我们仅需要编码器，而不需要解码器。</p><p>接下来让我们 dive into the details of VAE。论文的 introduction 部分我们略过，直接看 method 部分。</p><h2 id="method">2. Method</h2><p>本节中的策略可用于为具有连续潜在变量(隐变量)的各种有向图形模型推导下限估计器（随机目标函数）。我们在这里将自己限制在常见情况下：</p><ul><li>我们有一个 i.i.d. 数据集，每个数据点都有潜在变量。</li><li>我们希望对（全局）参数执行最大似然（ML）或最大后验（MAP）推理，以及对潜在变量进行变分推理。</li></ul><p>这里的潜在变量是什么就很值得玩味了。</p><h3 id="问题场景problem-scenario">2.1 问题场景(Problem Scenario)</h3><p>让我们考虑一些数据集<span class="math inline">\(\mathbf{X} = \{\mathbf{x}^{(i)}\}_{i=1}^N\)</span>，它由一些连续或离散变量<span class="math inline">\(x\)</span>的<span class="math inline">\(N\)</span>个i.i.d.样本组成。</p><p>我们假设数据是由某个随机过程生成的，涉及一个未观察到的连续随机变量<span class="math inline">\(z\)</span>。该过程包括以下两个步骤：</p><p>1.从某个先验分布<span class="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{z})\)</span>生成一个值<span class="math inline">\(\mathbf{z}^{(i)}\)</span><br>2.值<span class="math inline">\(\mathbf{x}^{(i)}\)</span>是从某个条件分布<span class="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{x}|\mathbf{z})\)</span>生成的</p><p>我们假设先验<span class="math inline">\(p_{\boldsymbol{\theta}^* }(\mathbf{z})\)</span>和似然<span class="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{x}|\mathbf{z})\)</span>来自分布<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{z})\)</span>和<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)</span>的参数族，并且它们的概率密度函数（PDF）几乎在<span class="math inline">\(\boldsymbol{\theta}\)</span>和<span class="math inline">\(\mathbf{z}\)</span>的任何地方都是可微分的。</p><h4 id="隐藏的挑战">隐藏的挑战</h4><p>然而，不幸的是，这个过程的很多内容都隐藏在我们看不见的地方：</p><ul><li>我们不知道真实参数<span class="math inline">\(\boldsymbol{\theta}^*\)</span>。</li><li>我们也不知道潜在变量<span class="math inline">\(\mathbf{z}^{(i)}\)</span>的值。</li></ul><p>非常重要的是，我们没有对边际或后验概率做出常见的简化假设。相反，我们在这里对一种通用算法感兴趣，该算法甚至可以在以下情况下有效工作：</p><h4 id="难解性">难解性</h4><ul><li><p><strong>边际似然难以处理</strong>：<br>边际似然<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x}) = \int p_{\boldsymbol{\theta}}(\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})d\mathbf{z}\)</span>的积分难以处理，因此我们无法评估或区分边际似然。</p></li><li><p><strong>真实后验密度难以处理</strong>：<br>真实后验密度<span class="math display">\[p_{\boldsymbol{\theta}}(\mathbf{z}|\mathbf{x}) = \frac{p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{x})}\]</span>难以处理，因此不能使用期望最大算法。</p></li><li><p><strong>积分复杂性</strong>：<br>任何合理的均场变分贝叶斯推断算法所需的积分也难以处理。这些难解性很常见，出现在中等复杂似然函数<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)</span>的情况下，例如具有非线性隐藏层的神经网络。</p></li></ul><h4 id="数据集规模">数据集规模</h4><ul><li><p><strong>数据集过大</strong>：<br>数据太多，批量优化成本太高。我们希望使用小批量甚至单个数据点进行参数更新。</p></li><li><p><strong>基于采样的解决方案过慢</strong>：<br>基于采样的解决方案（例如蒙特卡罗期望最大算法）通常太慢，因为它通常涉及每个数据点昂贵的采样循环。</p></li></ul><h4 id="相关问题与解决方案">相关问题与解决方案</h4><p>我们对上述场景中的三个相关问题感兴趣，并提出了解决方案：</p><ol type="1"><li><p><strong>参数<span class="math inline">\(\boldsymbol{\theta}\)</span>的有效近似最大似然估计或最大后验估计估计</strong>：<br>参数本身可能很有趣，例如，如果我们正在分析一些自然过程。它们还允许我们模拟隐藏的随机过程并生成类似于真实数据的人工数据。</p></li><li><p><strong>潜在变量<span class="math inline">\(\mathbf{z}\)</span>的有效近似后验推断</strong>：<br>对于参数<span class="math inline">\(\boldsymbol{\theta}\)</span>的选择，给定观测值<span class="math inline">\(\mathbf{x}\)</span>，潜在变量<span class="math inline">\(\mathbf{z}\)</span>的有效近似后验推断。这对于编码或数据表示任务非常有用。</p></li><li><p><strong>变量<span class="math inline">\(\mathbf{x}\)</span>的有效近似边际推理</strong>：<br>这使我们能够执行需要通过先验<span class="math inline">\(\mathbf{x}\)</span>的各种推理任务。计算机视觉中的常见应用包括图像去噪、修复和超分辨率。</p></li></ol><p>为了解决上述问题，让我们引入一个识别模型<span class="math inline">\(q_{\phi}(z|x)\)</span>：这是对难以处理的真实后验分布<span class="math inline">\(p_{\theta}(z|x)\)</span>的一种近似。需要注意的是，与均值场变分推断中的近似后验不同，该模型不要求具有因子分解形式，其参数<span class="math inline">\(\phi\)</span>也不是通过闭式期望计算得到的。相反，我们将提出一种方法，<strong>使识别模型参数<span class="math inline">\(\phi\)</span>能够与生成模型参数<span class="math inline">\(\theta\)</span>被联合学习</strong>。</p><p>从编码理论的视角来看，未观测变量<span class="math inline">\(z\)</span>可以解释为潜在表示或编码。因此，在本文中，我们将识别模型<span class="math inline">\(q_{\phi}(z|x)\)</span>称为概率<strong>编码器</strong>——当给定数据点<span class="math inline">\(x\)</span>时，它会生成一个关于编码<span class="math inline">\(z\)</span>可能取值的分布（例如高斯分布），该编码能够生成数据点<span class="math inline">\(x\)</span>。类似地，我们将<span class="math inline">\(p_{\theta}(x|z)\)</span>称为概率<strong>解码器</strong>——当给定编码<span class="math inline">\(z\)</span>时，它会生成一个关于对应数据点<span class="math inline">\(x\)</span>可能取值的分布。</p><h3 id="变分界the-variational-bound">2.2 变分界(The variational bound)</h3><p>边际似然由各个数据点的边际似然之和构成<span class="math inline">\(\log p_{\theta}(x^{(1)}, \cdots, x^{(N)}) = \sum_{i=1}^{N} \log p_{\theta}(x^{(i)})\)</span>，其中每个项均可重写为： <span class="math display">\[\begin{align} &amp; \log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})=D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}} (\mathbf{z}|\mathbf{x}^{(i)}))+\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\tag{1} \end{align}\]</span></p><p>第一项的右侧是近似后验分布与真实后验分布之间的KL散度。由于该KL散度非负，第二项的右侧<span class="math inline">\(\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>被称为数据点 <span class="math inline">\(i\)</span> 边缘似然的（变分）下界，其表达式可表示为： <span class="math display">\[ \log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})\geq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})}\left[-\log q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})+\log p_{\boldsymbol{\theta}}(\mathbf{x},\mathbf{z})\right]\tag{2} \]</span></p><p>也可以写成如下形式： <span class="math display">\[ \mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=-D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))+\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z})\right]\tag{3} \]</span></p><p>我们需要对下界 <span class="math inline">\(\mathcal{L}(\theta, \phi; \mathbf{x}^{(i)})\)</span> 关于变分参数 <span class="math inline">\(\phi\)</span> 和生成参数 <span class="math inline">\(\theta\)</span> 进行微分和优化。然而，下界关于 <span class="math inline">\(\phi\)</span> 的梯度计算存在一定问题。针对此类问题的常规（朴素）蒙特卡洛梯度估计器为：</p><p><span class="math display">\[ \nabla_{\boldsymbol{\phi}}\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z})}\left[f(\mathbf{z})\right]=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z})}\left[f(\mathbf{z})\nabla_{q_{\boldsymbol{\phi}}(\mathbf{z})}\log q_{\boldsymbol{\phi}}(\mathbf{z})\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(\mathbf{z})\nabla_{q_{\boldsymbol{\phi}}(\mathbf{z}^{(l)})}\log q_{\boldsymbol{\phi}}(\mathbf{z}^{(l)}) \]</span></p><p>其中 <span class="math inline">\(\mathbf{z}^{(l)} \sim q_\phi(\mathbf{z} | \mathbf{x}^{(i)})\)</span>。</p><p>该梯度估计器的方差极高，因此在实际应用中难以有效使用。</p><h3 id="sgvb估计器随机梯度变分贝叶斯估计器stochastic-gradient-variational-bayes-和-aevb算法自动编码变分贝叶斯auto-encoding-variational-bayes">2.3 SGVB估计器（随机梯度变分贝叶斯估计器，Stochastic Gradient Variational Bayes 和 AEVB算法（自动编码变分贝叶斯，Auto-Encoding Variational Bayes</h3><p>本节我们将介绍一种针对变分下界及其参数导数的实用估计方法。我们采用条件近似后验分布<span class="math inline">\(q_\phi(\mathbf{z} | \mathbf{x})\)</span>的形式，但需要注意的是，该技术同样适用于非条件形式<span class="math inline">\(q_\phi(\mathbf{z})\)</span>（即不依赖于x的情况）。</p><p>在满足第2.4节所述的特定温和条件下，对于选定的近似后验分布<span class="math inline">\(q_\phi(\mathbf{z} | \mathbf{x})\)</span>，我们可以通过一个可微变换<span class="math inline">\(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x})\)</span>对随机变量<span class="math inline">\(\widetilde{\mathbf{z}}\sim q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>进行重新参数化，其中<span class="math inline">\(\epsilon\)</span>是一个辅助噪声变量： <span class="math display">\[ \widetilde{\mathbf{z}}=g_\phi(\boldsymbol{\epsilon},\mathbf{x})\quad\mathrm{with~}\quad\boldsymbol{\epsilon}\sim p(\boldsymbol{\epsilon})\tag{4} \]</span></p><p>关于如何选择合适的分布 <span class="math inline">\(p(\boldsymbol{\epsilon})\)</span> 和函数 <span class="math inline">\(g_\phi(\boldsymbol{\epsilon},\mathbf{x})\)</span> 的一般性策略，请参阅第 2.4 节的内容。基于此，我们可以按以下方式构建关于 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> 的期望函数 <span class="math inline">\(f(z)\)</span> 的蒙特卡洛估计： <span class="math display">\[ \mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[f(\mathbf{z})\right]=\mathbb{E}_{p(\boldsymbol{\epsilon})}\left[f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x}^{(i)}))\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(l)},\mathbf{x}^{(i)}))\quad\mathrm{where}\quad\boldsymbol{\epsilon}^{(l)}\sim p(\boldsymbol{\epsilon})\tag{5} \]</span></p><p>我们运用这一技术处理变分下界（公式(2)），由此得到通用的随机梯度变分贝叶斯（SGVB）估计量 <span class="math inline">\(\widetilde{\mathcal{L}}^A(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\simeq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>，其表达式为： <span class="math display">\[\begin{aligned} &amp; \widetilde{\mathcal{L}}^A(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=\frac{1}{L}\sum_{l=1}^L\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)},\mathbf{z}^{(i,l)})-\log q_{\boldsymbol{\phi}}(\mathbf{z}^{(i,l)}|\mathbf{x}^{(i)}) \\ &amp; \mathrm{where}\quad\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(i,l)},\mathbf{x}^{(i)})\quad\mathrm{and}\quad\boldsymbol{\epsilon}^{(l)}\sim p(\boldsymbol{\epsilon}) \end{aligned}\tag{6} \]</span></p><p>通常，公式(3)中的KL散度<span class="math inline">\(D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))\)</span>可以解析计算，因此只需通过采样估计期望重构误差<span class="math inline">\(\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z})\right]\)</span>。此时，KL散度项可解释为对<span class="math inline">\(\phi\)</span>的正则化项，促使近似后验分布接近先验分布<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{z})\)</span>。由此可以得到SGVB估计量的第二个版本<span class="math inline">\(\widetilde{\mathcal{L}}^B(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\simeq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>，对应公式(3)，该估计量通常比通用估计量具有更小的方差： <span class="math display">\[\begin{aligned} &amp; \widetilde{\mathcal{L}}^B(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=-D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))+\frac{1}{L}\sum_{l=1}^L(\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})) \\ &amp; \mathrm{where}\quad\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(i,l)},\mathbf{x}^{(i)})\quad\mathrm{and}\quad\boldsymbol{\epsilon}^{(l)}\sim p(\boldsymbol{\epsilon}) \end{aligned}\tag{7} \]</span></p><p>对于包含<span class="math inline">\(N\)</span>个数据的数据集<span class="math inline">\(X\)</span>，在给定多个数据的情况下，我们可以基于小批量数据构建完整数据集边际似然下界的估计量： <span class="math display">\[\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{X})\simeq\widetilde{\mathcal{L}}^M(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{X}^M)=\frac{N}{M}\sum_{i=1}^M\widetilde{\mathcal{L}}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\tag{8} \]</span> 其中，小批量数据<span class="math inline">\(\mathbf{X}^M=\{\mathbf{x}^{(i)}\}_{i=1}^M\)</span>是从包含<span class="math inline">\(N\)</span>个数据的完整数据集<span class="math inline">\(X\)</span>中随机抽取的<span class="math inline">\(M\)</span>个数据点子集。实验结果表明，只要小批量规模<span class="math inline">\(M\)</span>足够大（例如<span class="math inline">\(M\)</span>=100），每个数据的样本数<span class="math inline">\(L\)</span>可设为1。我们可以计算梯度<span class="math inline">\(\nabla_{\boldsymbol{\theta},\boldsymbol{\phi}}\widetilde{\mathcal{L}}(\boldsymbol{\theta};\mathbf{X}^M)\)</span>，并将所得梯度与随机优化方法（如SGD或Adagrad）结合使用。随机梯度的基本计算方法请参见<strong>Algorithm 1</strong>。</p><p><img src="/assets/images/vae-algorithm.png" srcset="/img/loading.gif" lazyload></p><p>当我们分析公式(7)给出的目标函数时，其与自编码器的关联就变得清晰可见。其中，第一项（近似后验分布与先验分布的KL散度）充当正则化项，而第二项则是期望负重构误差。函数<span class="math inline">\(g_{\phi}(.)\)</span>的设计使得它能将数据点<span class="math inline">\(x^{(i)}\)</span>和随机噪声向量<span class="math inline">\(\epsilon^{(l)}\)</span>映射为该数据点的近似后验分布样本：<span class="math inline">\(\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(l)},\mathbf{x}^{(i)})\)</span>，其中<span class="math inline">\(\mathbf{z}^{(i,l)}\sim q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})\)</span>。随后，样本<span class="math inline">\(z^{(i,l)}\)</span>被输入函数<span class="math inline">\(\log p_\theta(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})\)</span>，该函数表示在生成模型中给定<span class="math inline">\(\mathbf{z}^{(i,l)}\)</span>时数据点<span class="math inline">\(\mathbf{x}^{(i)}\)</span>的概率密度（或质量）。用自编码器的术语来说，这一项就是负<em>重构误差</em>。</p><h3 id="重参数化技巧">2.4 重参数化技巧</h3><p>为解决这一问题，我们采用了一种从条件分布<span class="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span>中生成样本的替代方法。这一核心的重参数化技巧原理其实非常简单：假设 <span class="math inline">\(\mathbf{z}\)</span> 是一个连续随机变量，且<span class="math inline">\(\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})\)</span>为某个条件分布。此时通常可以将随机变量 <span class="math inline">\(\mathbf{z}\)</span> 重新表达为一个确定性变量：<span class="math inline">\(z = g_\phi(\epsilon,\mathbf{x})\)</span>，其中 <span class="math inline">\(\epsilon\)</span> 是一个具有独立边界<span class="math inline">\(p(\epsilon)\)</span>的辅助变量，并且<span class="math inline">\(g_\phi(.)\)</span>是由<span class="math inline">\(\phi\)</span>参数化的某个向量值函数。</p><p>该重参数化方法之所以适用于我们的情况，是因为它能将关于<span class="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span>的期望改写成可对<span class="math inline">\(\phi\)</span>求导的形式，从而使得蒙特卡洛估计对<span class="math inline">\(\phi\)</span>可微。具体证明如下：给定确定性映射关系 <span class="math inline">\(\mathbf{z} = g_\phi(\epsilon,\mathbf{x})\)</span>，根据概率密度变换关系可得： <span class="math inline">\(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\prod_idz_i=p(\boldsymbol{\epsilon})\prod_id\epsilon_i\)</span> 因此(请注意，对于无穷小，我们使用 <span class="math inline">\(d\mathbf{z}=\prod_idz_i\)</span>)，期望可被重写为： <span class="math display">\[ \int q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})f(\mathbf{z}) d\mathbf{z} = \int p(\boldsymbol{\epsilon})f(\mathbf{z}) d\boldsymbol{\epsilon} = \int p(\boldsymbol{\epsilon})f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x})) d\boldsymbol{\epsilon} \]</span></p><p>由此可得，我们可以构建一个可微估计量： <span class="math display">\[ \int q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})f(\mathbf{z}) d\mathbf{z} \simeq \frac{1}{L} \sum_{l=1}^L f(g_{\boldsymbol{\phi}}(\boldsymbol{\mathbf{x},\epsilon}^{(l)})) \]</span> 其中，<span class="math inline">\(\boldsymbol{\epsilon}^{(l)} \sim p(\epsilon)\)</span>。在2.3节中，我们应用这一技巧得到了变分下界的可微估计量。</p><p>以单变量高斯分布为例：设 <span class="math inline">\(\mathbf{z}\sim p(\mathbf{z}|\mathbf{x})=\mathcal{N}(\mu,\sigma^{2})\)</span>。此时，一个有效的重参数化形式为 <span class="math inline">\(z=\mu+\sigma\epsilon\)</span>，其中 <span class="math inline">\(\epsilon\)</span> 是辅助噪声变量 <span class="math inline">\(\epsilon\sim\mathcal{N}(0,1)\)</span>。因此，其期望可表示为： <span class="math display">\[ \begin{array}{r}{\mathbb{E}_{\mathcal{N}(z;\mu,\sigma^{2})}\left[f(z)\right]=\mathbb{E}_{\mathcal{N}(\epsilon;0,1)}\left[f(\mu+\sigma\epsilon)\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(\mu+\sigma\epsilon^{(l)})}\end{array} \]</span> 其中 <span class="math inline">\(\epsilon^{(l)}\sim\mathcal{N}(0,1)\)</span>。</p><p>对于条件分布 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>，我们可以选择这样的可微变换 <span class="math inline">\(g_{\phi}(\cdot)\)</span> 和辅助变量 <span class="math inline">\(\epsilon\sim p(\epsilon)\)</span>吗？主要有以下三种基本方法：</p><ol type="1"><li><p><strong>可逆 累积分布函数法（CDF）</strong>：若 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> 存在易处理的逆CDF，设 <span class="math inline">\(\epsilon\sim\mathcal{U}(\mathbf{0},\mathbf{I})\)</span>，令 <span class="math inline">\(g_{\phi}(\epsilon,\mathbf{x})\)</span> 为该分布的逆CDF。<br>适用分布：指数分布、柯西分布、逻辑斯谛分布、瑞利分布、帕累托分布、威布尔分布、倒数分布、冈珀茨分布、冈贝尔分布和埃尔朗分布。</p></li><li><p><strong>位置-尺度分布族通用解法</strong>：<br>类比高斯分布案例，对于任何”位置-尺度”族分布，均可按以下方式构造重参数化：<br>设标准分布（位置参数 <span class="math inline">\(\mathit{\theta}=0\)</span>，尺度参数 <span class="math inline">\(\lambda=1\)</span>）为辅助变量 <span class="math inline">\(\epsilon\)</span> 定义变换函数 <span class="math inline">\(g(\cdot) = \mu + \sigma \cdot \epsilon\)</span> 其中 <span class="math inline">\(\mu\)</span> 为位置参数，<span class="math inline">\(\sigma\)</span> 为尺度参数<br>适用分布：拉普拉斯分布、椭圆分布、学生t分布、逻辑斯谛分布、均匀分布、三角分布和高斯分布。</p></li><li><p><strong>组合变换法</strong>：通过辅助变量的复合变换实现，常见形式包括：<br>对数正态分布（正态分布变量的指数变换），伽马分布（多个指数分布变量的和），狄利克雷分布（伽马变量的加权和），贝塔分布、卡方分布、F分布等</p></li></ol><p>当上述三种方法均不适用时，仍可通过计算复杂度与概率密度函数（PDF）相当的数值方法来获得逆累积分布函数（inverse CDF）的高精度近似解。</p><p>至此，总算到了我们关心的部分。</p><h2 id="例子变分自编码器">3. 例子：变分自编码器</h2><p>在本节中，我们将给出一个应用示例：使用神经网络构建概率编码器 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>（作为生成模型 <span class="math inline">\(p_{\pmb{\theta}}(\mathbf{x},\mathbf{z})\)</span> 后验分布的近似），并通过AEVB算法联合优化参数 <span class="math inline">\(\phi\)</span> 和 <span class="math inline">\(\pmb{\theta}\)</span>。</p><p>设隐变量的先验分布为中心各向同性多元高斯分布 <span class="math inline">\(p_{\pmb{\theta}}(\mathbf{z}) = \mathcal{N}(\mathbf{z};\mathbf{0},{\mathbf{I}})\)</span>。需要注意的是，这种情况下先验分布不含参数。我们令 <span class="math inline">\(p_{\pmb{\theta}}(\mathbf{x}|\mathbf{z})\)</span> 为多元高斯分布（实值数据）或伯努利分布（二值数据），其分布参数通过一个MLP从 <span class="math inline">\(\mathbf{z}\)</span> 计算得到。需要注意的是，真实后验 <span class="math inline">\(p_{\pmb{\theta}}(\mathbf{z}|\mathbf{x})\)</span> 在这种情况下是难以处理的。</p><p>虽然 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> 的形式选择具有很大自由度，但我们假设真实（但难以处理的）后验服从近似高斯形式且具有近似对角协方差矩阵。在这种情况下，我们可以设变分近似后验为具有对角协方差结构的多元高斯分布（请注意，这只是一个（简化的）选择，而不是我们方法的限制）： <span class="math display">\[ \log q_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})=\log\mathcal{N}(\mathbf{z};\pmb{\mu}^{(i)},\pmb{\sigma}^{2(i)}\mathbf{I})\tag{9} \]</span> 如第2.4节所述，我们使用<span class="math display">\[ \mathbf{z}^{(i,l)} = g_{\phi}(\mathbf{x}^{(i)},\epsilon^{(l)}) = \pmb{\mu}^{(i)} + \pmb{\sigma}^{(i)} \odot \pmb{\epsilon}^{(l)} \]</span>从后验分布<span class="math inline">\(\mathbf{z}^{(i,l)}\sim q_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})\)</span>中采样，其中 <span class="math inline">\(\epsilon^{(l)} \sim \mathcal{N}(\mathbf{0},\mathbf{I})\)</span>，符号 <span class="math inline">\(\odot\)</span> 表示逐元素乘积。在该模型中：先验分布 <span class="math inline">\(p_{\pmb{\theta}}(\mathbf{z})\)</span> 与近似后验 <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> 均为高斯分布,可直接计算KL散度（无需估计）并求导,基于公式(7)的估计量，对数据 <span class="math inline">\(\mathbf{x}^{(i)}\)</span> 的最终估计式为： <span class="math display">\[ \begin{array}{r l}&amp;{\mathcal{L}(\pmb{\theta},\phi;\mathbf{x}^{(i)})\simeq\displaystyle\frac{1}{2}\sum_{j=1}^{J}\left(1+\log((\sigma_{j}^{(i)})^{2})-(\mu_{j}^{(i)})^{2}-(\sigma_{j}^{(i)})^{2}\right)+\frac{1}{L}\sum_{l=1}^{L}\log p_{\pmb{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})}\\ &amp;{\mathrm{where}\quad\mathbf{z}^{(i,l)}=\pmb{\mu}^{(i)}+\pmb{\sigma}^{(i)}\odot\pmb{\epsilon}^{(l)}\quad\mathrm{and}\quad\pmb{\epsilon}^{(l)}\sim\mathcal{N}(0,\mathbf{I})}\end{array}\tag{10} \]</span><br>如上所述，解码项<span class="math inline">\(\log p_{\pmb{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})\)</span>根据建模数据类型的不同，可表现为伯努利MLP或高斯MLP的形式。</p><p>余下部分就不详细展开了。</p><h2 id="我的总结">4. 我的总结</h2><h3 id="要讲vae首先得聊聊ae">要讲VAE,首先得聊聊AE。</h3><p>AE（Autoencoder）由两个主要组件组成：编码器<span class="math inline">\(\mathbf{z}=f_{\phi}(\mathbf{x})\)</span>和解码器<span class="math inline">\(\mathbf{x}=g_{\theta}(\mathbf{z})\)</span>。编码器的目标是将输入数据<span class="math inline">\(\mathbf{x}\)</span>映射到一个低维的潜在表示<span class="math inline">\(\mathbf{z}\)</span>，而解码器的目标是将潜在表示<span class="math inline">\(\mathbf{z}\)</span>映射回原始数据空间<span class="math inline">\(\mathbf{x}\)</span>。AE通常使用的Loss函数是<span class="math inline">\(\ell=\|X-\tilde{X}\|^2\)</span>。</p><h2 id="一些可能有帮助的资料">5. 一些可能有帮助的资料</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/348498294">机器学习方法—优雅的模型（一）：变分自编码器（VAE）</a> <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1aE411o7qd/?p=170">机器学习-白板推导系列-变分自编码器</a></p></div><hr><div><div class="post-metas my-3"><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/AI/" class="print-no-link">#AI</a> <a href="/tags/math/" class="print-no-link">#math</a> <a href="/tags/VAE/" class="print-no-link">#VAE</a></div></div><div class="license-box my-3"><div class="license-title"><div>变分自编码器</div><div>https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html</div></div><div class="license-meta"><div class="license-meta-item"><div>Author</div><div>Peidong Chen</div></div><div class="license-meta-item license-meta-date"><div>Posted on</div><div>March 28, 2025</div></div><div class="license-meta-item license-meta-date"><div>Updated on</div><div>April 13, 2025</div></div><div class="license-meta-item"><div>Licensed under</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - Attribution"><i class="iconfont icon-cc-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2025/03/09/The-way-to-Artificial-Intelligence.html" title="人工智能基础"><span class="hidden-mobile">人工智能基础</span> <span class="visible-mobile">Next</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><div id="gitalk-container"></div><script>Fluid.utils.loadComments("#gitalk-container",function(){Fluid.utils.createCssLink("/css/gitalk.css"),Fluid.utils.createScript("https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js",function(){var e=Object.assign({clientID:"Ov23ctnrThuBni26Ofso",clientSecret:"4d4b389bab01995e80c741eb49ae380bbbb5d4ef",repo:"Pd-ch.github.io",owner:"Pd-ch",admin:["Pd-ch"],language:"zh-CN",labels:["Gitalk"],perPage:10,pagerDirection:"last",distractionFreeMode:!1,createIssueManually:!0,proxy:"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},{id:"3"});new Gitalk(e).render("gitalk-container")})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>Table of Contents</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">Search</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">Keyword</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content">&copy; 2025 Pd-ch's Blog, Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t=t.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback(function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())})</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">Blog works best with JavaScript enabled</div></noscript><script>(()=>{function u(t,r){return parseInt(t.substr(r,2),16)}document.querySelectorAll("a").forEach(function(t){var r=(t=>{if(!t)return t;for(var r="",e=u(t=t.substr(1),0),n=2;n<t.length;n+=2)r+=String.fromCharCode(u(t,n)^e);return r})(t.getAttribute("href"));r&&r.startsWith("mailto:")&&t.setAttribute("href",r)})})()</script></body></html>