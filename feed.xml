<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Pd-ch&#39;s Blog</title>
  
  <subtitle>Stay hungry. Stay foolish.</subtitle>
  <link href="https://pd-ch.github.io/feed.xml" rel="self"/>
  
  <link href="https://pd-ch.github.io/"/>
  <updated>2025-04-08T12:42:01.866Z</updated>
  <id>https://pd-ch.github.io/</id>
  
  <author>
    <name>Peidong Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>变分自编码器</title>
    <link href="https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html"/>
    <id>https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html</id>
    <published>2025-03-28T00:00:00.000Z</published>
    <updated>2025-04-08T12:42:01.866Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明本文是对变分自编码器的学习总结">说明：本文是对变分自编码器的学习总结</h6><span id="more"></span><p>论文链接：<a href="https://arxiv.org/abs/1312.6114">🔗</a></p><hr /><h2 id="当我们谈论-vae-时我们在谈论什么">当我们谈论 VAE时，我们在谈论什么？</h2><p>变分自编码器（VariationalAutoencoder，VAE）是一种生成模型，它通过学习数据的潜在表示来生成新的数据样本。VAE的主要目标是找到一个潜在变量的分布，使得原始数据可以被表示为这个分布的概率分布。</p><p>通常的 VAE模型包括一个编码器（Encoder）和一个解码器（Decoder）。而在无监督方法中，我们仅需要编码器，而不需要解码器。</p><p>接下来让我们 dive into the details of VAE。论文的 introduction部分我们略过，直接看 method 部分。</p><hr /><h2 id="method">Method</h2><p>本节中的策略可用于为具有连续潜在变量(隐变量)的各种有向图形模型推导下限估计器（随机目标函数）。我们在这里将自己限制在常见情况下：</p><ul><li>我们有一个 i.i.d. 数据集，每个数据点都有潜在变量。</li><li>我们希望对（全局）参数执行最大似然（ML）或最大后验（MAP）推理，以及对潜在变量进行变分推理。</li></ul><p>这里的潜在变量是什么就很值得玩味了。</p><h3 id="问题场景problem-scenario">问题场景(Problem Scenario)</h3><p>让我们考虑一些数据集 $ = {^{(i)}}_{i=1}^N $，它由一些连续或离散变量 $x $ 的 $ N $ 个 i.i.d. 样本组成。</p><p>我们假设数据是由某个随机过程生成的，涉及一个未观察到的连续随机变量 $z $。该过程包括以下两个步骤：</p><ol type="1"><li>**从某个先验分布 $ p_{^*}() $ 生成一个值 $ ^{(i)} $**<br /></li><li><strong>值 <span class="math display">\[ \mathbf{x}^{(i)} \]</span>是从某个条件分布 <spanclass="math display">\[p_{\boldsymbol{\theta}^*}(\mathbf{x}|\mathbf{z})\]</span>生成的</strong></li></ol><p>我们假设先验 $ p_{^<em>}() $ 和似然 $ p_{^</em>}(|) $ 来自分布 $p_{}() $ 和 $ p_{}(|) $ 的参数族，并且它们的概率密度函数（PDF）几乎在 $$ 和 $ $ 的任何地方都是可微分的。</p><h4 id="隐藏的挑战">隐藏的挑战</h4><p>然而，不幸的是，这个过程的很多内容都隐藏在我们看不见的地方：</p><ul><li>我们不知道真实参数 $ ^* $。</li><li>我们也不知道潜在变量 $ ^{(i)} $ 的值。</li></ul><p>非常重要的是，我们没有对边际或后验概率做出常见的简化假设。相反，我们在这里对一种通用算法感兴趣，该算法甚至可以在以下情况下有效工作：</p><h4 id="难解性">难解性</h4><ul><li><p><strong>边际似然难以处理</strong>：<br />边际似然 $ p_{}() = p_{}()p_{}(|)d $的积分难以处理，因此我们无法评估或区分边际似然。</p></li><li><p><strong>真实后验密度难以处理</strong>：<br />真实后验密度 $ p_{}(|) = $ 难以处理，因此不能使用期望最大算法。</p></li><li><p><strong>积分复杂性</strong>：<br />任何合理的均场变分贝叶斯推断算法所需的积分也难以处理。这些难解性很常见，出现在中等复杂似然函数$ p_{}(|) $ 的情况下，例如具有非线性隐藏层的神经网络。</p></li></ul><h4 id="数据集规模">数据集规模</h4><ul><li><p><strong>数据集过大</strong>：<br />数据太多，批量优化成本太高。我们希望使用小批量甚至单个数据点进行参数更新。</p></li><li><p><strong>基于采样的解决方案过慢</strong>：<br />基于采样的解决方案（例如蒙特卡罗期望最大算法）通常太慢，因为它通常涉及每个数据点昂贵的采样循环。</p></li></ul><h4 id="相关问题与解决方案">相关问题与解决方案</h4><p>我们对上述场景中的三个相关问题感兴趣，并提出了解决方案：</p><ol type="1"><li><p><strong>参数 $ $的有效近似最大似然估计或最大后验估计估计</strong>：<br />参数本身可能很有趣，例如，如果我们正在分析一些自然过程。它们还允许我们模拟隐藏的随机过程并生成类似于真实数据的人工数据。</p></li><li><p><strong>潜在变量 $ $ 的有效近似后验推断</strong>：<br />对于参数 $ $ 的选择，给定观测值 $ $，潜在变量 $ $的有效近似后验推断。这对于编码或数据表示任务非常有用。</p></li><li><p><strong>变量 $ $ 的有效近似边际推理</strong>：<br />这使我们能够执行需要通过先验 $ $的各种推理任务。计算机视觉中的常见应用包括图像去噪、修复和超分辨率。</p></li></ol><p>为了解决上述问题，让我们引入一个识别模型<spanclass="math inline">\(q_{\phi}(z|x)\)</span>：这是对难以处理的真实后验分布<spanclass="math inline">\(p_{\theta}(z|x)\)</span>的一种近似。需要注意的是，与均值场变分推断中的近似后验不同，该模型不要求具有因子分解形式，其参数<spanclass="math inline">\(\phi\)</span>也不是通过闭式期望计算得到的。相反，我们将提出一种方法，使识别模型参数<spanclass="math inline">\(\phi\)</span>能够与生成模型参数<spanclass="math inline">\(\theta\)</span>被联合学习。</p><p>从编码理论的视角来看，未观测变量<spanclass="math inline">\(z\)</span>可以解释为潜在表示或编码。因此，在本文中，我们将识别模型<spanclass="math inline">\(q_{\phi}(z|x)\)</span>称为概率<strong>编码器</strong>——当给定数据点<spanclass="math inline">\(x\)</span>时，它会生成一个关于编码<spanclass="math inline">\(z\)</span>可能取值的分布（例如高斯分布），该编码能够生成数据点<spanclass="math inline">\(x\)</span>。类似地，我们将<spanclass="math inline">\(p_{\theta}(x|z)\)</span>称为概率<strong>解码器</strong>——当给定编码<spanclass="math inline">\(z\)</span>时，它会生成一个关于对应数据点<spanclass="math inline">\(x\)</span>可能取值的分布。</p><h3 id="变分界the-variational-bound">变分界(The variational bound)</h3><p>边际似然由各个数据点的边际似然之和构成<spanclass="math inline">\(\log p_{\theta}(x^{(1)}, \cdots, x^{(N)}) =\sum_{i=1}^{N} \log p_{\theta}(x^{(i)})\)</span>，其中每个项均可重写为：<span class="math display">\[\begin{aligned}  &amp; \logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})=D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}|\mathbf{x}^{(i)}))+\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\tag{1}\end{aligned}\]</span></p>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明本文是对变分自编码器的学习总结&quot;&gt;说明：本文是对变分自编码器的学习总结&lt;/h6&gt;</summary>
    
    
    
    
    <category term="AI" scheme="https://pd-ch.github.io/tags/AI/"/>
    
    <category term="math" scheme="https://pd-ch.github.io/tags/math/"/>
    
    <category term="VAE" scheme="https://pd-ch.github.io/tags/VAE/"/>
    
  </entry>
  
  <entry>
    <title>人工智能基础</title>
    <link href="https://pd-ch.github.io/2025/03/09/The-way-to-Artificial-Intelligence.html"/>
    <id>https://pd-ch.github.io/2025/03/09/The-way-to-Artificial-Intelligence.html</id>
    <published>2025-03-09T00:00:00.000Z</published>
    <updated>2025-04-08T12:42:01.866Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明介绍目前的深度学习需要学习什么以及一些比较好的资源">说明：介绍目前的深度学习需要学习什么，以及一些比较好的资源。</h6><span id="more"></span><blockquote><h2 id="基础技术栈">基础技术栈</h2><ul><li><strong>系统</strong>：Debian<br /></li><li><strong>环境管理</strong>：venv，pip<br /></li><li><strong>编程语言</strong>：Python<br /></li><li><strong>AI 框架</strong>：Pytorch<br /></li><li><strong>内容管理工具</strong>：Git<br /></li><li><strong>集成开发环境</strong>：VScode（本地环境）、Jupyterlab（远程环境）</li></ul></blockquote><blockquote><h2 id="进阶技术栈">进阶技术栈</h2><ul><li><strong>编程语言</strong>：C++（g++、cling，标准=20）<br /></li><li><strong>AI 框架</strong>：Pytorch（AMP，DDP并发）<br /></li><li><strong>环境管理</strong>：Docker（开发容器与普通容器）<br /></li><li><strong>高性能计算</strong>：jax<br /></li><li><strong>大数据</strong>：duckdb（替代pandas）<br /></li><li><strong>构建工具</strong>：xmake</li></ul></blockquote><blockquote><h2 id="自选方向技术栈">自选方向技术栈</h2><ul><li><strong>数学建模</strong>：MATLAB / Mworks（Julia）<br /></li><li><strong>大数据</strong>：pyspark<br /></li><li><strong>科学计算</strong>：计算方法，Julia<br /></li><li><strong>云计算</strong>：K8s（rancher）、KVM、SDS（ceph）、SDN<br /></li><li><strong>边缘智能</strong>：Tensort、onnx<br /></li><li><strong>高性能AI</strong>：flax、optax、orbax</li><li><strong>加速器</strong>：FPGA（xilinx）、vitis、PCIe</li></ul></blockquote><blockquote><p><strong>注：</strong><br />1. 基础技术栈建议在进入方向后3-6个月内完成；<br />2. 进阶技术栈建议在基础学习完后1-2个月内完成；<br />3. 自选方向技术栈仅作为参考，目前阶段无强制要求；<br />4. 使用“/”连接表示可选择其中一种技术，使用“，”仅作为分隔符；<br />5. WSL2不再推荐，仅作为过渡使用。</p></blockquote><hr /><h3 id="以下推荐一些需要的数学知识">以下推荐一些需要的数学知识</h3><ul><li><strong><ahref="https://www.zhihu.com/column/gs-linear-algebra">线性代数</a></strong>：介绍了人工智能所需的线性代数基础</li><li><strong><ahref="https://www.zhihu.com/column/c_1334301979816820736">机器学习方法</a></strong>：深入介绍机器学习中的一些基础方法</li></ul>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明介绍目前的深度学习需要学习什么以及一些比较好的资源&quot;&gt;说明：介绍目前的深度学习需要学习什么，以及一些比较好的资源。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="AI" scheme="https://pd-ch.github.io/tags/AI/"/>
    
    <category term="math" scheme="https://pd-ch.github.io/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>简单介绍一下我本人的环境搭建</title>
    <link href="https://pd-ch.github.io/2024/09/29/My-environment-setup.html"/>
    <id>https://pd-ch.github.io/2024/09/29/My-environment-setup.html</id>
    <published>2024-09-29T00:00:00.000Z</published>
    <updated>2025-04-08T12:42:01.866Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明仅介绍本人主要使用的配置留档以便后来可快速配置">说明：仅介绍本人主要使用的配置，留档以便后来可快速配置。</h6><span id="more"></span><h3 id="目录">目录</h3><ul><li><a href="#step-0-系统启动盘制作">Step 0. 系统启动盘制作</a></li><li><a href="#step-1-终端美化与代理设置">Step 1.终端美化与代理设置</a></li><li><a href="#step-2-安装NVIDIA驱动">Step 2. 安装NVIDIA驱动</a></li><li><a href="#step-3-安装python环境管理工具">Step 3.安装python环境管理工具</a></li></ul><h2 id="step-0.-系统启动盘制作">Step 0. 系统启动盘制作</h2><p>简单来说，Ventoy是一个制作可启动U盘的开源工具。有了Ventoy你就无需反复地格式化U盘，你只需要把ISO/WIM/IMG/VHD(x)/EFI等类型的文件直接拷贝到U盘里面就可以启动了，无需其他操作。你可以一次性拷贝很多个不同类型的镜像文件，Ventoy会在启动时显示一个菜单来供你进行选择。 下载地址:<ahref="https://www.ventoy.net/cn/download.html"class="uri">https://www.ventoy.net/cn/download.html</a>安装到U盘以后，只需要将iso镜像复制到U盘中即可。个人建议前往镜像站下载操作系统的iso镜像。</p><p>安装过程因人而异，故此不再赘述。个人比较喜欢Debian，在安装进行到分区这一步时，建议删除除引导分区以外的其它分区，我们不需要swap，以及这样做方便我们创建Btrfs主分区，将它的挂载点设置在“/”下。完成安装。(建议使用DVD镜像，避免安装时过多的等待)</p><p>接着进入系统，切换为root用户，为自己创建的用户添加sudo权限，并进行换源。此处不再赘述。值得一提的是，换源不再建议使用tuna(清华)源(用的人太多了，容易断流)。</p><p>至此，我们的系统就初步配置好了。</p><h2 id="step-1.-终端美化与代理设置">Step 1. 终端美化与代理设置</h2><p>终端个人推荐使用zsh，主题使用powerlevel10k，插件仅需zsh-autosuggestions与zsh-syntax-highlighting即可。配置可参照:<a href="https://www.haoyep.com/posts/zsh-config-oh-my-zsh/"class="uri">https://www.haoyep.com/posts/zsh-config-oh-my-zsh/</a></p><p>代理的设置建议如下 新建<strong>~/scripts/proxy.sh</strong>,并在该脚本文件中复制以下代码,其中hostip和port按需更改:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br>hostip=127.0.0.1<br>port=7890<br><br>PROXY_HTTP=<span class="hljs-string">&quot;http://<span class="hljs-variable">$&#123;hostip&#125;</span>:<span class="hljs-variable">$&#123;port&#125;</span>&quot;</span><br><br><span class="hljs-function"><span class="hljs-title">set_proxy</span></span>()&#123;<br>  <span class="hljs-built_in">export</span> http_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> HTTP_PROXY=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br><br>  <span class="hljs-built_in">export</span> https_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> HTTPS_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br><br>  <span class="hljs-built_in">export</span> ALL_PROXY=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_SOCKS5&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> all_proxy=<span class="hljs-variable">$&#123;PROXY_SOCKS5&#125;</span><br><br>  git config --global http.https://github.com.proxy <span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span><br>  git config --global https.https://github.com.proxy <span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span><br><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy has been opened.&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">unset_proxy</span></span>()&#123;<br>  <span class="hljs-built_in">unset</span> http_proxy<br>  <span class="hljs-built_in">unset</span> HTTP_PROXY<br>  <span class="hljs-built_in">unset</span> https_proxy<br>  <span class="hljs-built_in">unset</span> HTTPS_PROXY<br>  <span class="hljs-built_in">unset</span> ALL_PROXY<br>  <span class="hljs-built_in">unset</span> all_proxy<br>  git config --global --<span class="hljs-built_in">unset</span> http.https://github.com.proxy<br>  git config --global --<span class="hljs-built_in">unset</span> https.https://github.com.proxy<br><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy has been closed.&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">test_setting</span></span>()&#123;<br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Host IP:&quot;</span> <span class="hljs-variable">$&#123;hostip&#125;</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Try to connect to Google...&quot;</span><br>  resp=$(curl -I -s --connect-timeout 5 -m 5 -w <span class="hljs-string">&quot;%&#123;http_code&#125;&quot;</span> -o /dev/null www.google.com)<br>  <span class="hljs-keyword">if</span> [ <span class="hljs-variable">$&#123;resp&#125;</span> = 200 ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy setup succeeded!&quot;</span><br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy setup failed!&quot;</span><br>  <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;set&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  set_proxy<br><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;unset&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  unset_proxy<br><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;test&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  test_setting<br><span class="hljs-keyword">else</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Unsupported arguments.&quot;</span><br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure> 在你的.zshrc或者.bashrc中添加<strong>alias proxy=“source~/scripts/proxy.sh”</strong></p><p>使用时只需要在终端输入proxy set;proxy unset;proxy test.</p><p>至此,终端美化与代理设置就初步完成了</p><h2 id="step-2.-安装nvidia驱动">Step 2. 安装NVIDIA驱动</h2><p>你完全可以<strong>sudo apt installnvidia-driver</strong>来安装开源驱动但是我更推荐安装闭源驱动，如果有内核更新，记得要<strong>sudo apt installlinux-headers-$(uname -r)</strong>.</p><p>安装 apt GPG keyring 包，目的是获取 GPG 密钥 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget https:<span class="hljs-regexp">//</span>developer.download.nvidia.com<span class="hljs-regexp">/compute/</span>cuda<span class="hljs-regexp">/repos/</span>debian12<span class="hljs-regexp">/x86_64/</span>cuda-keyring_1.<span class="hljs-number">1</span>-<span class="hljs-number">1</span>_all.deb<br>sudo dpkg -i cuda-keyring_1.<span class="hljs-number">1</span>-<span class="hljs-number">1</span>_all.deb<br></code></pre></td></tr></table></figure></p><p>可以到此位置<ahref="https://developer.download.nvidia.com/compute/cuda/repos/"class="uri">https://developer.download.nvidia.com/compute/cuda/repos/</a>浏览具体发行版</p><p>apt 安装驱动 <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">sudo apt update<br>sudo apt -y <span class="hljs-keyword">install</span> nvidia-driver cuda-drivers<br></code></pre></td></tr></table></figure></p><p>至此,你已经几乎完成了环境的搭建。</p><h2 id="step-3.-安装python环境管理工具">Step 3.安装python环境管理工具</h2><p>这个看个人品味,我推荐使用miniconda,venv或者mamba.镜像站使用tuna或者bfsu.在此笔者假设读者熟悉上面三种的任意一种创建完虚拟的环境后,进入虚拟环境对pip进行换源.直接运行 <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> torch<br></code></pre></td></tr></table></figure>如果在安装完torch后安装了大量nvidia*的包,那么就可以放心了,你安装的是pytorchwith GPU</p><h5id="你已经完成了深度学习环境搭建立刻开始愉快的学习吧">你已经完成了深度学习环境搭建,立刻开始愉快的学习吧！</h5>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明仅介绍本人主要使用的配置留档以便后来可快速配置&quot;&gt;说明：仅介绍本人主要使用的配置，留档以便后来可快速配置。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="env setup" scheme="https://pd-ch.github.io/tags/env-setup/"/>
    
  </entry>
  
  <entry>
    <title>Intel A770 GPU深度学习环境搭建（Linux）</title>
    <link href="https://pd-ch.github.io/2024/06/28/A770_deeplearning_env_setup.html"/>
    <id>https://pd-ch.github.io/2024/06/28/A770_deeplearning_env_setup.html</id>
    <published>2024-06-28T00:00:00.000Z</published>
    <updated>2025-04-08T12:42:01.865Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明windows下也可以进行环境搭建但是个人更偏爱debian">说明：Windows下也可以进行环境搭建，但是个人更偏爱Debian。</h6><h6id="updatepytorch在24年10月中旬发布了2.5版本添加了intel-gpu支持使用以下代码以启用."><strong>Update:pytorch在24年10月中旬发布了2.5版本,添加了IntelGPU支持,使用以下代码以启用.</strong></h6><p>这是pytorch官方的链接<ahref="https://pytorch.org/docs/main/notes/get_start_xpu.html"class="uri">https://pytorch.org/docs/main/notes/get_start_xpu.html</a></p><p>我们需要准备好GPU驱动,oneAPI.(不过现在仍然处于Preview版本)<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">pip3 install torch torchvision torchaudio --index-url https:<span class="hljs-regexp">//</span>download.pytorch.org<span class="hljs-regexp">/whl/</span>test/xpu<br></code></pre></td></tr></table></figure></p><h6id="以下外国博客也可参考我仍然只推荐使用torch2.5preview"><strong>以下外国博客也可参考,我仍然只推荐使用torch2.5preview</strong></h6><p><ahref="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/"class="uri">https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/</a></p><h3 id="目录">目录</h3><ul><li><a href="#step-0-准备工作">Step 0. 准备工作</a></li><li><a href="#step-1-安装GPU驱动">Step 1. 安装GPU驱动</a></li><li><a href="#step-2-安装Intel®-oneAPI-Base-Toolkit">Step 2.安装Intel®-oneAPI-Base-Toolkit</a></li><li><a href="#step-3-安装Intel®-Extension-for-PyTorch">Step 3.安装Intel®-Extension-forPyTorch</a></li><li><a href="#step-4-安装xpu-smi">Step 4. 安装xpu-smi</a></li></ul><h2 id="step-0.-准备工作">Step 0. 准备工作</h2><p>首先你需要有一台使用Intel GPU的电脑，本文针对Intel ArcA770（16GB）编写，系统环境为Debian sid。</p><p>关于Intel® Extension for PyTorch的安装可以参考官方示例<ahref="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.1.30%2bxpu&amp;os=linux%2fwsl2&amp;package=pip"class="uri">https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.1.30%2bxpu&amp;os=linux%2fwsl2&amp;package=pip</a>。以下部分是我自己踩的一点坑。</p><h2 id="step-1.-安装gpu驱动">step 1. 安装GPU驱动</h2><p>前往<ahref="https://dgpu-docs.intel.com/driver/client/overview.html">IntelGPU驱动网站</a>，进行其中的3.1.1-3.1.5部分。树外内核部分无需理会。</p><h2 id="step-2.-安装intel-oneapi-base-toolkit">step 2.安装Intel®-oneAPI-Base-Toolkit</h2><p>前往<ahref="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html?operatingsystem=linux&amp;linux-install-type=apt">Intel®-oneAPI-Base-Toolkit</a>网站，使用apt进行安装。</p><h2 id="step-3.-安装intel-extension-forpytorch">step 3.安装Intel®-Extension-forPyTorch</h2><p>我选择的是使用pip进行安装。你可以先使用conda创建一个虚拟环境，python版本推荐3.11。安装命令 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">python</span> -m pip install torch==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.post2 torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span>.post2 torchaudio==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.post2 intel-extension-for-pytorch==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">30</span>.post0 oneccl_bind_pt==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">300</span>+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/<br></code></pre></td></tr></table></figure></p><p>完成后进行测试。</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">source</span> <span class="hljs-regexp">/opt/i</span>ntel<span class="hljs-regexp">/oneapi/</span>setvars.sh<br></code></pre></td></tr></table></figure><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss">python -c &quot;import torch; import intel_extension_for_pytorch as ipex; <span class="hljs-built_in">print</span>(torch.__version__); <span class="hljs-built_in">print</span>(ipex.__version__); <span class="hljs-selector-attr">[print(f<span class="hljs-string">&#x27;[&#123;i&#125;]: &#123;torch.xpu.get_device_properties(i)&#125;&#x27;</span>) for i in range(torch.xpu.device_count())]</span>;&quot;<br></code></pre></td></tr></table></figure><p>最后成功识别到显卡即为安装成功。</p><p>前往<ahref="https://intel.github.io/intel-extension-for-pytorch/xpu/2.1.30+xpu/tutorials/examples.html">example</a>进行愉快的玩耍吧。</p><h1 id="step-4.-安装xpu-smi">step 4. 安装xpu-smi</h1><p>最后一部分我也还在摸索。使用这个软件也是因为intel-gpu-tools查看不了显存使用情况。</p><p>前往<ahref="https://github.com/intel/xpumanager/releases/tag/V1.2.37">release</a>页面下载安装即可。</p><p>使用说明在GitHub仓库的readme中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h6
id=&quot;说明windows下也可以进行环境搭建但是个人更偏爱debian&quot;&gt;说明：Windows下也可以进行环境搭建，但是个人更偏爱Debian。&lt;/h6&gt;
&lt;h6
id=&quot;updatepytorch在24年10月中旬发布了2.5版本添加了intel-gpu支持使用以下代</summary>
      
    
    
    
    
    <category term="env setup" scheme="https://pd-ch.github.io/tags/env-setup/"/>
    
    <category term="intel GPU" scheme="https://pd-ch.github.io/tags/intel-GPU/"/>
    
  </entry>
  
</feed>
