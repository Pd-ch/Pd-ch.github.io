<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Pd-ch&#39;s Blog</title>
  
  <subtitle>Stay hungry. Stay foolish.</subtitle>
  <link href="https://pd-ch.github.io/feed.xml" rel="self"/>
  
  <link href="https://pd-ch.github.io/"/>
  <updated>2025-06-18T09:46:18.734Z</updated>
  <id>https://pd-ch.github.io/</id>
  
  <author>
    <name>Peidong Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Auto-Encoding Variational Bayes</title>
    <link href="https://pd-ch.github.io/2025/06/18/arxiv-1312-6114v11.html"/>
    <id>https://pd-ch.github.io/2025/06/18/arxiv-1312-6114v11.html</id>
    <published>2025-06-18T09:46:18.734Z</published>
    <updated>2025-06-18T09:46:18.734Z</updated>
    
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2><p>论文的 introduction 部分我们略过，直接看 method 部分。</p><h2 id="method">2. Method</h2><p>本节中的策略可用于为具有连续潜在变量(隐变量)的各种有向图形模型推导下限估计器（随机目标函数）。我们在这里将自己限制在常见情况下：</p><ul><li>我们有一个 i.i.d. 数据集，每个数据点都有潜在变量。</li><li>我们希望对（全局）参数执行最大似然（ML）或最大后验（MAP）推理，以及对潜在变量进行变分推理。</li></ul><p>这里的潜在变量是什么就很值得玩味了。</p><h3 id="问题场景problem-scenario">2.1 问题场景(Problem Scenario)</h3><p>让我们考虑一些数据集<span class="math inline">\(\mathbf{X} =\{\mathbf{x}^{(i)}\}_{i=1}^N\)</span>，它由一些连续或离散变量<spanclass="math inline">\(x\)</span>的<spanclass="math inline">\(N\)</span>个i.i.d.样本组成。</p><p>我们假设数据是由某个随机过程生成的，涉及一个未观察到的连续随机变量<spanclass="math inline">\(z\)</span>。该过程包括以下两个步骤：</p><p>1.从某个先验分布<spanclass="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{z})\)</span>生成一个值<spanclass="math inline">\(\mathbf{z}^{(i)}\)</span><br />2.值<spanclass="math inline">\(\mathbf{x}^{(i)}\)</span>是从某个条件分布<spanclass="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{x}|\mathbf{z})\)</span>生成的</p><p>我们假设先验<span class="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{z})\)</span>和似然<spanclass="math inline">\(p_{\boldsymbol{\theta}^*}(\mathbf{x}|\mathbf{z})\)</span>来自分布<spanclass="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{z})\)</span>和<spanclass="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)</span>的参数族，并且它们的概率密度函数（PDF）几乎在<spanclass="math inline">\(\boldsymbol{\theta}\)</span>和<spanclass="math inline">\(\mathbf{z}\)</span>的任何地方都是可微分的。</p><h4 id="隐藏的挑战">隐藏的挑战</h4><p>然而，不幸的是，这个过程的很多内容都隐藏在我们看不见的地方：</p><ul><li>我们不知道真实参数<spanclass="math inline">\(\boldsymbol{\theta}^*\)</span>。</li><li>我们也不知道潜在变量<spanclass="math inline">\(\mathbf{z}^{(i)}\)</span>的值。</li></ul><p>非常重要的是，我们没有对边际或后验概率做出常见的简化假设。相反，我们在这里对一种通用算法感兴趣，该算法甚至可以在以下情况下有效工作：</p><h4 id="难解性">难解性</h4><ul><li><p><strong>边际似然难以处理</strong>：<br />边际似然<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x})= \intp_{\boldsymbol{\theta}}(\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})d\mathbf{z}\)</span>的积分难以处理，因此我们无法评估或区分边际似然。</p></li><li><p><strong>真实后验密度难以处理</strong>：<br />真实后验密度<spanclass="math display">\[p_{\boldsymbol{\theta}}(\mathbf{z}|\mathbf{x}) =\frac{p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{x})}\]</span>难以处理，因此不能使用期望最大算法。</p></li><li><p><strong>积分复杂性</strong>：<br />任何合理的均场变分贝叶斯推断算法所需的积分也难以处理。这些难解性很常见，出现在中等复杂似然函数<spanclass="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)</span>的情况下，例如具有非线性隐藏层的神经网络。</p></li></ul><h4 id="数据集规模">数据集规模</h4><ul><li><p><strong>数据集过大</strong>：<br />数据太多，批量优化成本太高。我们希望使用小批量甚至单个数据点进行参数更新。</p></li><li><p><strong>基于采样的解决方案过慢</strong>：<br />基于采样的解决方案（例如蒙特卡罗期望最大算法）通常太慢，因为它通常涉及每个数据点昂贵的采样循环。</p></li></ul><h4 id="相关问题与解决方案">相关问题与解决方案</h4><p>我们对上述场景中的三个相关问题感兴趣，并提出了解决方案：</p><ol type="1"><li><p><strong>参数<spanclass="math inline">\(\boldsymbol{\theta}\)</span>的有效近似最大似然估计或最大后验估计估计</strong>：<br />参数本身可能很有趣，例如，如果我们正在分析一些自然过程。它们还允许我们模拟隐藏的随机过程并生成类似于真实数据的人工数据。</p></li><li><p><strong>潜在变量<spanclass="math inline">\(\mathbf{z}\)</span>的有效近似后验推断</strong>：<br />对于参数<spanclass="math inline">\(\boldsymbol{\theta}\)</span>的选择，给定观测值<spanclass="math inline">\(\mathbf{x}\)</span>，潜在变量<spanclass="math inline">\(\mathbf{z}\)</span>的有效近似后验推断。这对于编码或数据表示任务非常有用。</p></li><li><p><strong>变量<spanclass="math inline">\(\mathbf{x}\)</span>的有效近似边际推理</strong>：<br />这使我们能够执行需要通过先验<spanclass="math inline">\(\mathbf{x}\)</span>的各种推理任务。计算机视觉中的常见应用包括图像去噪、修复和超分辨率。</p></li></ol><p>为了解决上述问题，让我们引入一个识别模型<spanclass="math inline">\(q_{\phi}(z|x)\)</span>：这是对难以处理的真实后验分布<spanclass="math inline">\(p_{\theta}(z|x)\)</span>的一种近似。需要注意的是，与均值场变分推断中的近似后验不同，该模型不要求具有因子分解形式，其参数<spanclass="math inline">\(\phi\)</span>也不是通过闭式期望计算得到的。相反，我们将提出一种方法，<strong>使识别模型参数<spanclass="math inline">\(\phi\)</span>能够与生成模型参数<spanclass="math inline">\(\theta\)</span>被联合学习</strong>。</p><p>从编码理论的视角来看，未观测变量<spanclass="math inline">\(z\)</span>可以解释为潜在表示或编码。因此，在本文中，我们将识别模型<spanclass="math inline">\(q_{\phi}(z|x)\)</span>称为概率<strong>编码器</strong>——当给定数据点<spanclass="math inline">\(x\)</span>时，它会生成一个关于编码<spanclass="math inline">\(z\)</span>可能取值的分布（例如高斯分布），该编码能够生成数据点<spanclass="math inline">\(x\)</span>。类似地，我们将<spanclass="math inline">\(p_{\theta}(x|z)\)</span>称为概率<strong>解码器</strong>——当给定编码<spanclass="math inline">\(z\)</span>时，它会生成一个关于对应数据点<spanclass="math inline">\(x\)</span>可能取值的分布。</p><h3 id="变分界the-variational-bound">2.2 变分界(The variationalbound)</h3><p>边际似然由各个数据点的边际似然之和构成<spanclass="math inline">\(\log p_{\theta}(x^{(1)}, \cdots, x^{(N)}) =\sum_{i=1}^{N} \log p_{\theta}(x^{(i)})\)</span>，其中每个项均可重写为：<span class="math display">\[\begin{align} &amp;    \logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})=D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}    (\mathbf{z}|\mathbf{x}^{(i)}))+\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\tag{1}\end{align}\]</span></p><p>第一项的右侧是近似后验分布与真实后验分布之间的KL散度。由于该KL散度非负，第二项的右侧<spanclass="math inline">\(\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>被称为数据点<span class="math inline">\(i\)</span>边缘似然的（变分）下界，其表达式可表示为： <span class="math display">\[    \logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})\geq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})}\left[-\logq_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})+\logp_{\boldsymbol{\theta}}(\mathbf{x},\mathbf{z})\right]\tag{2}\]</span></p><p>也可以写成如下形式： <span class="math display">\[    \mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=-D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))+\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[\logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z})\right]\tag{3}\]</span></p><p>我们需要对下界 <span class="math inline">\(\mathcal{L}(\theta, \phi;\mathbf{x}^{(i)})\)</span> 关于变分参数 <spanclass="math inline">\(\phi\)</span> 和生成参数 <spanclass="math inline">\(\theta\)</span> 进行微分和优化。然而，下界关于<span class="math inline">\(\phi\)</span>的梯度计算存在一定问题。针对此类问题的常规（朴素）蒙特卡洛梯度估计器为：</p><p><span class="math display">\[    \nabla_{\boldsymbol{\phi}}\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z})}\left[f(\mathbf{z})\right]=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z})}\left[f(\mathbf{z})\nabla_{q_{\boldsymbol{\phi}}(\mathbf{z})}\logq_{\boldsymbol{\phi}}(\mathbf{z})\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(\mathbf{z})\nabla_{q_{\boldsymbol{\phi}}(\mathbf{z}^{(l)})}\logq_{\boldsymbol{\phi}}(\mathbf{z}^{(l)})\]</span></p><p>其中 <span class="math inline">\(\mathbf{z}^{(l)} \simq_\phi(\mathbf{z} | \mathbf{x}^{(i)})\)</span>。</p><p>该梯度估计器的方差极高，因此在实际应用中难以有效使用。</p><h3id="sgvb估计器随机梯度变分贝叶斯估计器stochastic-gradient-variational-bayes-和-aevb算法自动编码变分贝叶斯auto-encoding-variational-bayes">2.3SGVB估计器（随机梯度变分贝叶斯估计器，Stochastic Gradient VariationalBayes） 和 AEVB算法（自动编码变分贝叶斯，Auto-Encoding VariationalBayes）</h3><p>本节我们将介绍一种针对变分下界及其参数导数的实用估计方法。我们采用条件近似后验分布<spanclass="math inline">\(q_\phi(\mathbf{z} |\mathbf{x})\)</span>的形式，但需要注意的是，该技术同样适用于非条件形式<spanclass="math inline">\(q_\phi(\mathbf{z})\)</span>（即不依赖于x的情况）。</p><p>在满足第2.4节所述的特定温和条件下，对于选定的近似后验分布<spanclass="math inline">\(q_\phi(\mathbf{z} |\mathbf{x})\)</span>，我们可以通过一个可微变换<spanclass="math inline">\(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x})\)</span>对随机变量<spanclass="math inline">\(\widetilde{\mathbf{z}}\simq_{\phi}(\mathbf{z}|\mathbf{x})\)</span>进行重新参数化，其中<spanclass="math inline">\(\epsilon\)</span>是一个辅助噪声变量： <spanclass="math display">\[    \widetilde{\mathbf{z}}=g_\phi(\boldsymbol{\epsilon},\mathbf{x})\quad\mathrm{with~}\quad\boldsymbol{\epsilon}\simp(\boldsymbol{\epsilon})\tag{4}\]</span></p><p>关于如何选择合适的分布 <spanclass="math inline">\(p(\boldsymbol{\epsilon})\)</span> 和函数 <spanclass="math inline">\(g_\phi(\boldsymbol{\epsilon},\mathbf{x})\)</span>的一般性策略，请参阅第 2.4 节的内容。基于此，我们可以按以下方式构建关于<span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>的期望函数 <span class="math inline">\(f(z)\)</span> 的蒙特卡洛估计：<span class="math display">\[    \mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[f(\mathbf{z})\right]=\mathbb{E}_{p(\boldsymbol{\epsilon})}\left[f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x}^{(i)}))\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(l)},\mathbf{x}^{(i)}))\quad\mathrm{where}\quad\boldsymbol{\epsilon}^{(l)}\simp(\boldsymbol{\epsilon})\tag{5}\]</span></p><p>我们运用这一技术处理变分下界（公式(2)），由此得到通用的随机梯度变分贝叶斯（SGVB）估计量<spanclass="math inline">\(\widetilde{\mathcal{L}}^A(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\simeq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>，其表达式为：<span class="math display">\[\begin{aligned}&amp;\widetilde{\mathcal{L}}^A(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=\frac{1}{L}\sum_{l=1}^L\logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)},\mathbf{z}^{(i,l)})-\logq_{\boldsymbol{\phi}}(\mathbf{z}^{(i,l)}|\mathbf{x}^{(i)}) \\&amp;\mathrm{where}\quad\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(i,l)},\mathbf{x}^{(i)})\quad\mathrm{and}\quad\boldsymbol{\epsilon}^{(l)}\simp(\boldsymbol{\epsilon})\end{aligned}\tag{6}\]</span></p><p>通常，公式(3)中的KL散度<spanclass="math inline">\(D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))\)</span>可以解析计算，因此只需通过采样估计期望重构误差<spanclass="math inline">\(\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[\logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z})\right]\)</span>。此时，KL散度项可解释为对<spanclass="math inline">\(\phi\)</span>的正则化项，促使近似后验分布接近先验分布<spanclass="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{z})\)</span>。由此可以得到SGVB估计量的第二个版本<spanclass="math inline">\(\widetilde{\mathcal{L}}^B(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\simeq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span>，对应公式(3)，该估计量通常比通用估计量具有更小的方差：<span class="math display">\[\begin{aligned}&amp;\widetilde{\mathcal{L}}^B(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=-D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))+\frac{1}{L}\sum_{l=1}^L(\logp_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})) \\&amp;\mathrm{where}\quad\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(i,l)},\mathbf{x}^{(i)})\quad\mathrm{and}\quad\boldsymbol{\epsilon}^{(l)}\simp(\boldsymbol{\epsilon})\end{aligned}\tag{7}\]</span></p><p>对于包含<span class="math inline">\(N\)</span>个数据的数据集<spanclass="math inline">\(X\)</span>，在给定多个数据的情况下，我们可以基于小批量数据构建完整数据集边际似然下界的估计量：<spanclass="math display">\[\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{X})\simeq\widetilde{\mathcal{L}}^M(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{X}^M)=\frac{N}{M}\sum_{i=1}^M\widetilde{\mathcal{L}}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\tag{8}\]</span> 其中，小批量数据<spanclass="math inline">\(\mathbf{X}^M=\{\mathbf{x}^{(i)}\}_{i=1}^M\)</span>是从包含<spanclass="math inline">\(N\)</span>个数据的完整数据集<spanclass="math inline">\(X\)</span>中随机抽取的<spanclass="math inline">\(M\)</span>个数据点子集。实验结果表明，只要小批量规模<spanclass="math inline">\(M\)</span>足够大（例如<spanclass="math inline">\(M\)</span>=100），每个数据的样本数<spanclass="math inline">\(L\)</span>可设为1。我们可以计算梯度<spanclass="math inline">\(\nabla_{\boldsymbol{\theta},\boldsymbol{\phi}}\widetilde{\mathcal{L}}(\boldsymbol{\theta};\mathbf{X}^M)\)</span>，并将所得梯度与随机优化方法（如SGD或Adagrad）结合使用。随机梯度的基本计算方法请参见<strong>Algorithm1</strong>。</p><p><img src="/assets/images/vae-algorithm.png" /></p><p>当我们分析公式(7)给出的目标函数时，其与自编码器的关联就变得清晰可见。其中，第一项（近似后验分布与先验分布的KL散度）充当正则化项，而第二项则是期望负重构误差。函数<spanclass="math inline">\(g_{\phi}(.)\)</span>的设计使得它能将数据点<spanclass="math inline">\(x^{(i)}\)</span>和随机噪声向量<spanclass="math inline">\(\epsilon^{(l)}\)</span>映射为该数据点的近似后验分布样本：<spanclass="math inline">\(\mathbf{z}^{(i,l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(l)},\mathbf{x}^{(i)})\)</span>，其中<spanclass="math inline">\(\mathbf{z}^{(i,l)}\simq_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})\)</span>。随后，样本<spanclass="math inline">\(z^{(i,l)}\)</span>被输入函数<spanclass="math inline">\(\logp_\theta(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})\)</span>，该函数表示在生成模型中给定<spanclass="math inline">\(\mathbf{z}^{(i,l)}\)</span>时数据点<spanclass="math inline">\(\mathbf{x}^{(i)}\)</span>的概率密度（或质量）。用自编码器的术语来说，这一项就是负<em>重构误差</em>。</p><h3 id="重参数化技巧">2.4 重参数化技巧</h3><p>为解决这一问题，我们采用了一种从条件分布<spanclass="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span>中生成样本的替代方法。这一核心的重参数化技巧原理其实非常简单：假设<span class="math inline">\(\mathbf{z}\)</span>是一个连续随机变量，且<span class="math inline">\(\mathbf{z} \simq_\phi(\mathbf{z}|\mathbf{x})\)</span>为某个条件分布。此时通常可以将随机变量<span class="math inline">\(\mathbf{z}\)</span>重新表达为一个确定性变量：<span class="math inline">\(z =g_\phi(\epsilon,\mathbf{x})\)</span>，其中 <spanclass="math inline">\(\epsilon\)</span> 是一个具有独立边界<spanclass="math inline">\(p(\epsilon)\)</span>的辅助变量，并且<spanclass="math inline">\(g_\phi(.)\)</span>是由<spanclass="math inline">\(\phi\)</span>参数化的某个向量值函数。</p><p>该重参数化方法之所以适用于我们的情况，是因为它能将关于<spanclass="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span>的期望改写成可对<spanclass="math inline">\(\phi\)</span>求导的形式，从而使得蒙特卡洛估计对<spanclass="math inline">\(\phi\)</span>可微。具体证明如下：给定确定性映射关系<span class="math inline">\(\mathbf{z} =g_\phi(\epsilon,\mathbf{x})\)</span>，根据概率密度变换关系可得： <spanclass="math inline">\(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\prod_idz_i=p(\boldsymbol{\epsilon})\prod_id\epsilon_i\)</span>因此(请注意，对于无穷小，我们使用 <spanclass="math inline">\(d\mathbf{z}=\prod_idz_i\)</span>)，期望可被重写为：<span class="math display">\[\int q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})f(\mathbf{z})d\mathbf{z} = \int p(\boldsymbol{\epsilon})f(\mathbf{z})d\boldsymbol{\epsilon} = \intp(\boldsymbol{\epsilon})f(g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\mathbf{x}))d\boldsymbol{\epsilon}\]</span></p><p>由此可得，我们可以构建一个可微估计量： <span class="math display">\[\int q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})f(\mathbf{z})d\mathbf{z} \simeq \frac{1}{L} \sum_{l=1}^Lf(g_{\boldsymbol{\phi}}(\boldsymbol{\mathbf{x},\epsilon}^{(l)}))\]</span> 其中，<span class="math inline">\(\boldsymbol{\epsilon}^{(l)}\simp(\epsilon)\)</span>。在2.3节中，我们应用这一技巧得到了变分下界的可微估计量。</p><p>以单变量高斯分布为例：设 <span class="math inline">\(\mathbf{z}\simp(\mathbf{z}|\mathbf{x})=\mathcal{N}(\mu,\sigma^{2})\)</span>。此时，一个有效的重参数化形式为<span class="math inline">\(z=\mu+\sigma\epsilon\)</span>，其中 <spanclass="math inline">\(\epsilon\)</span> 是辅助噪声变量 <spanclass="math inline">\(\epsilon\sim\mathcal{N}(0,1)\)</span>。因此，其期望可表示为：<span class="math display">\[\begin{array}{r}{\mathbb{E}_{\mathcal{N}(z;\mu,\sigma^{2})}\left[f(z)\right]=\mathbb{E}_{\mathcal{N}(\epsilon;0,1)}\left[f(\mu+\sigma\epsilon)\right]\simeq\frac{1}{L}\sum_{l=1}^{L}f(\mu+\sigma\epsilon^{(l)})}\end{array}\]</span> 其中 <spanclass="math inline">\(\epsilon^{(l)}\sim\mathcal{N}(0,1)\)</span>。</p><p>对于条件分布 <spanclass="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>，我们可以选择这样的可微变换<span class="math inline">\(g_{\phi}(\cdot)\)</span> 和辅助变量 <spanclass="math inline">\(\epsilon\simp(\epsilon)\)</span>吗？主要有以下三种基本方法：</p><ol type="1"><li><p><strong>可逆 累积分布函数法（CDF）</strong>：若 <spanclass="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>存在易处理的逆CDF，设 <spanclass="math inline">\(\epsilon\sim\mathcal{U}(\mathbf{0},\mathbf{I})\)</span>，令<span class="math inline">\(g_{\phi}(\epsilon,\mathbf{x})\)</span>为该分布的逆CDF。<br />适用分布：指数分布、柯西分布、逻辑斯谛分布、瑞利分布、帕累托分布、威布尔分布、倒数分布、冈珀茨分布、冈贝尔分布和埃尔朗分布。</p></li><li><p><strong>位置-尺度分布族通用解法</strong>：<br />类比高斯分布案例，对于任何”位置-尺度”族分布，均可按以下方式构造重参数化：<br />设标准分布（位置参数 <spanclass="math inline">\(\mathit{\theta}=0\)</span>，尺度参数 <spanclass="math inline">\(\lambda=1\)</span>）为辅助变量 <spanclass="math inline">\(\epsilon\)</span> 定义变换函数 <spanclass="math inline">\(g(\cdot) = \mu + \sigma \cdot \epsilon\)</span>其中 <span class="math inline">\(\mu\)</span> 为位置参数，<spanclass="math inline">\(\sigma\)</span> 为尺度参数<br />适用分布：拉普拉斯分布、椭圆分布、学生t分布、逻辑斯谛分布、均匀分布、三角分布和高斯分布。</p></li><li><p><strong>组合变换法</strong>：通过辅助变量的复合变换实现，常见形式包括：<br />对数正态分布（正态分布变量的指数变换），伽马分布（多个指数分布变量的和），狄利克雷分布（伽马变量的加权和），贝塔分布、卡方分布、F分布等</p></li></ol><p>当上述三种方法均不适用时，仍可通过计算复杂度与概率密度函数（PDF）相当的数值方法来获得逆累积分布函数（inverseCDF）的高精度近似解。</p><p>至此，总算到了我们关心的部分。</p><h2 id="例子变分自编码器">3. 例子：变分自编码器</h2><p>在本节中，我们将给出一个应用示例：使用神经网络构建概率编码器 <spanclass="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>（作为生成模型<spanclass="math inline">\(p_{\pmb{\theta}}(\mathbf{x},\mathbf{z})\)</span>后验分布的近似），并通过AEVB算法联合优化参数 <spanclass="math inline">\(\phi\)</span> 和 <spanclass="math inline">\(\pmb{\theta}\)</span>。</p><p>设隐变量的先验分布为中心各向同性多元高斯分布 <spanclass="math inline">\(p_{\pmb{\theta}}(\mathbf{z}) =\mathcal{N}(\mathbf{z};\mathbf{0},{\mathbf{I}})\)</span>。需要注意的是，这种情况下先验分布不含参数。我们令<spanclass="math inline">\(p_{\pmb{\theta}}(\mathbf{x}|\mathbf{z})\)</span>为多元高斯分布（实值数据）或伯努利分布（二值数据），其分布参数通过一个MLP从<span class="math inline">\(\mathbf{z}\)</span>计算得到。需要注意的是，真实后验 <spanclass="math inline">\(p_{\pmb{\theta}}(\mathbf{z}|\mathbf{x})\)</span>在这种情况下是难以处理的。</p><p>虽然 <spanclass="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>的形式选择具有很大自由度，但我们假设真实（但难以处理的）后验服从近似高斯形式且具有近似对角协方差矩阵。在这种情况下，我们可以设变分近似后验为具有对角协方差结构的多元高斯分布（请注意，这只是一个（简化的）选择，而不是我们方法的限制）：<span class="math display">\[\logq_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})=\log\mathcal{N}(\mathbf{z};\pmb{\mu}^{(i)},\pmb{\sigma}^{2(i)}\mathbf{I})\tag{9}\]</span> 如第2.4节所述，我们使用<span class="math display">\[\mathbf{z}^{(i,l)} = g_{\phi}(\mathbf{x}^{(i)},\epsilon^{(l)}) =\pmb{\mu}^{(i)} + \pmb{\sigma}^{(i)} \odot \pmb{\epsilon}^{(l)}\]</span>从后验分布<span class="math inline">\(\mathbf{z}^{(i,l)}\simq_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})\)</span>中采样，其中 <spanclass="math inline">\(\epsilon^{(l)} \sim\mathcal{N}(\mathbf{0},\mathbf{I})\)</span>，符号 <spanclass="math inline">\(\odot\)</span>表示逐元素乘积。在该模型中：先验分布 <spanclass="math inline">\(p_{\pmb{\theta}}(\mathbf{z})\)</span> 与近似后验<span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>均为高斯分布,可直接计算KL散度（无需估计）并求导,基于公式(7)的估计量，对数据<span class="math inline">\(\mathbf{x}^{(i)}\)</span> 的最终估计式为：<span class="math display">\[\begin{array}{rl}&amp;{\mathcal{L}(\pmb{\theta},\phi;\mathbf{x}^{(i)})\simeq\displaystyle\frac{1}{2}\sum_{j=1}^{J}\left(1+\log((\sigma_{j}^{(i)})^{2})-(\mu_{j}^{(i)})^{2}-(\sigma_{j}^{(i)})^{2}\right)+\frac{1}{L}\sum_{l=1}^{L}\logp_{\pmb{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})}\\&amp;{\mathrm{where}\quad\mathbf{z}^{(i,l)}=\pmb{\mu}^{(i)}+\pmb{\sigma}^{(i)}\odot\pmb{\epsilon}^{(l)}\quad\mathrm{and}\quad\pmb{\epsilon}^{(l)}\sim\mathcal{N}(0,\mathbf{I})}\end{array}\tag{10}\]</span><br />如上所述，解码项<span class="math inline">\(\logp_{\pmb{\theta}}(\mathbf{x}^{(i)}|\mathbf{z}^{(i,l)})\)</span>根据建模数据类型的不同，可表现为伯努利MLP或高斯MLP的形式。</p><p>余下部分就不详细展开了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;论文的 introduction 部分我们略过，直接看 method 部分。&lt;/p&gt;
&lt;h2 id=&quot;method&quot;&gt;2. Method&lt;/h2&gt;
&lt;p&gt;本节中的策略可用于为具有连续潜在变量(隐</summary>
      
    
    
    
    
    <category term="AI" scheme="https://pd-ch.github.io/tags/AI/"/>
    
    <category term="math" scheme="https://pd-ch.github.io/tags/math/"/>
    
    <category term="unsupervised learning" scheme="https://pd-ch.github.io/tags/unsupervised-learning/"/>
    
    <category term="VAE" scheme="https://pd-ch.github.io/tags/VAE/"/>
    
  </entry>
  
  <entry>
    <title>Clang+Clangd+Xmake使用import std</title>
    <link href="https://pd-ch.github.io/2025/05/04/clang+clangd+xmake-import-std.html"/>
    <id>https://pd-ch.github.io/2025/05/04/clang+clangd+xmake-import-std.html</id>
    <published>2025-05-04T00:00:00.000Z</published>
    <updated>2025-06-18T09:46:18.733Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明本文介绍如何使用clangclangdxmake启用c-23新特性import-std">说明：本文介绍如何使用Clang+Clangd+Xmake启用C++-23新特性”importstd”。</h6><span id="more"></span><h2 id="环境配置">1. 环境配置</h2><p>我个人使用的环境是：</p><ul><li>Debian unstable</li><li>visual studio code</li><li>Clang 20.1.5</li><li>Clangd 20.1.5</li><li>Xmake 2.9.9</li></ul><h3 id="安装llvm全家桶">1.1 安装llvm全家桶</h3><p>根据<ahref="https://apt.llvm.org/">apt.llvm.org</a>的说明，添加llvm源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://apt.llvm.org/llvm.sh<br><span class="hljs-built_in">chmod</span> +x llvm.sh<br><span class="hljs-built_in">sudo</span> ./llvm.sh 20 all<br></code></pre></td></tr></table></figure><p><strong>注意</strong>：需要有对应的libc++-20-dev包。如果有任何疑问可以使用aptpolicy libc++-20-dev查看。</p><p><strong>警告</strong>：如果clang，clangd，与libc++-dev版本对不上，clangd就不能正常工作。</p><h3 id="安装xmake">1.2 安装xmake</h3><p>根据<ahref="https://xmake.io/#/zh-cn/guide/installation">xmake.io</a>的说明进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://xmake.io/shget.text -O - | bash<br></code></pre></td></tr></table></figure><h3 id="vscode-clangd-xmake配置">1.3 VSCode + Clangd + XMake配置</h3><p>可以参考<ahref="https://zhuanlan.zhihu.com/p/398790625">[万字长文]Visual StudioCode 配置 C/C++ 开发环境的最佳实践(VSCode + Clangd + XMake)</a>。</p><p>注意 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;clangd.arguments&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;--compile-commands-dir=$&#123;workspaceFolder&#125;/.vscode&quot;</span><span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure> 需要设置，否则clangd无法找到编译命令。</p><h2 id="启用import-std">2. 启用import std</h2><h3 id="配置xmake">2.1 配置xmake</h3><p>在xmake.lua中添加： <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs lua">add_rules(<span class="hljs-string">&quot;mode.debug&quot;</span>, <span class="hljs-string">&quot;mode.release&quot;</span>)<br>add_rules(<span class="hljs-string">&quot;plugin.compile_commands.autoupdate&quot;</span>, &#123; outputdir = <span class="hljs-string">&quot;./.vscode&quot;</span> &#125;)<br><br>set_plat(<span class="hljs-string">&quot;linux&quot;</span>)<br>set_toolchains(<span class="hljs-string">&quot;clang&quot;</span>)<br>set_runtimes(<span class="hljs-string">&quot;c++_static&quot;</span>)<br>set_config(<span class="hljs-string">&quot;sdk&quot;</span>, <span class="hljs-string">&quot;/usr/lib/llvm-20/&quot;</span>)<br><br>target(<span class="hljs-string">&quot;stdmodules&quot;</span>)<br>    set_kind(<span class="hljs-string">&quot;binary&quot;</span>)<br>    add_files(<span class="hljs-string">&quot;*.cpp&quot;</span>)<br>    set_languages(<span class="hljs-string">&quot;c++23&quot;</span>)<br>    set_policy(<span class="hljs-string">&quot;build.c++.modules&quot;</span>, <span class="hljs-literal">true</span>)<br>target_end()<br></code></pre></td></tr></table></figure></p><p>编写一个简单的程序： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">import</span> std;<br><br><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> -&gt; <span class="hljs-type">int</span> </span>&#123;<br>    std::<span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;Hello, World!&quot;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>此时你的项目结构应该是这样的： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">├── xmake.lua<br>└── main.cpp<br></code></pre></td></tr></table></figure></p><p>编译： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">xmake<br></code></pre></td></tr></table></figure></p><p>产物位于<strong>build/linux/x86_64/release/</strong>目录下。</p><h2 id="enjoy-it">enjoy it!</h2>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明本文介绍如何使用clangclangdxmake启用c-23新特性import-std&quot;&gt;说明：本文介绍如何使用Clang+Clangd+Xmake启用C++-23新特性”import
std”。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="C++" scheme="https://pd-ch.github.io/tags/C/"/>
    
    <category term="clang" scheme="https://pd-ch.github.io/tags/clang/"/>
    
    <category term="clangd" scheme="https://pd-ch.github.io/tags/clangd/"/>
    
    <category term="xmake" scheme="https://pd-ch.github.io/tags/xmake/"/>
    
    <category term="std module" scheme="https://pd-ch.github.io/tags/std-module/"/>
    
  </entry>
  
  <entry>
    <title>变分自编码器</title>
    <link href="https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html"/>
    <id>https://pd-ch.github.io/2025/03/28/Variational-Autoencoder.html</id>
    <published>2025-03-28T00:00:00.000Z</published>
    <updated>2025-06-18T09:46:18.733Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明作者并非深度学习方面的专家如有错误欢迎讨论">说明：作者并非深度学习方面的专家，如有错误欢迎讨论</h6><span id="more"></span><p>论文链接：<a href="https://papers.cool/arxiv/1312.6114">🔗</a></p><p>本人的关于论文的粗略翻译<ahref="/2025/04/15/arxiv-1312-6114v11">🔗</a></p><p>由于我个人是做自监督相关的，故本文仅介绍自监督(self-supervisedlearning,SSL)方面VAE提供了什么。<del>其实在自监督中我们仅仅用到了VAE，没有用到decoder</del></p><h2 id="背景">1. 背景</h2><p>在自监督学习中，能否利用无标注数据学习数据的隐式表示是很重要的，隐式数据表示的好坏直接决定了后续下游任务表现的上限。</p><h2 id="vae提供了什么">2. VAE提供了什么</h2><p>变分自编码器（VAE）在自监督学习中的应用主要通过利用无标注数据学习数据的隐式表示，结合生成模型与自监督任务的优势。VAE的编码器将输入数据压缩为低维隐变量分布（通常假设为高斯分布），通过解码器重构数据。隐空间（latentspace）的分布特性使其适合作为下游任务的通用特征。</p><p>VAE是如何将输入压缩到隐空间的呢？或者说它是怎样建模了一个足够好的隐空间？</p><p>对于通常的AutoEncoder，它构造了映射：<span class="math inline">\(f:X\to Z\)</span> ，表示输入 <span class="math inline">\(X\)</span>经过网络 <span class="math inline">\(f\)</span> 压缩为 <spanclass="math inline">\(Z\)</span> 。但是对于一张普通的1080p RGB图片来讲，所有可能性高达<spanclass="math inline">\(1920\times1080\times3\times2^8\)</span>。传统网络擅长构建一对一映射，在这里就会“水土不服”。那么，有什么办法解决这个问题吗？</p><p>VAE选择了对隐空间进行建模，假设后验 <spanclass="math inline">\(p(z|x)\)</span> 服从高斯分布。</p><p>但是这带来了问题：</p><ul><li><p><strong>边际似然难以处理</strong>：<br />边际似然<span class="math inline">\(p_{\boldsymbol{\theta}}(\mathbf{x})= \intp_{\boldsymbol{\theta}}(\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})d\mathbf{z}\)</span>的积分难以处理，因此我们无法评估或区分边际似然。</p></li><li><p><strong>真实后验密度难以处理</strong>：<br />真实后验密度<spanclass="math display">\[p_{\boldsymbol{\theta}}(\mathbf{z}|\mathbf{x}) =\frac{p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{x})}\]</span>难以处理，因此不能使用期望最大算法。</p></li></ul><p>VAE 通过编码器神经网络实现数据压缩： 1.<strong>输入映射</strong><br />输入数据 <spanclass="math inline">\(\mathbf{x}\)</span>如图像）通过编码器网络 <spanclass="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span>映射到<strong>隐变量的概率分布参数</strong>（通常是高斯分布）： <spanclass="math display">\[   \mu_\phi(\mathbf{x}), \sigma_\phi(\mathbf{x}) =\text{Encoder}_\phi(\mathbf{x})   \]</span> - <spanclass="math inline">\(\mu\)</span>：隐变量分布的均值向量<br />- <spanclass="math inline">\(\sigma\)</span>：标准差向量（决定不确定性）</p><ol start="2" type="1"><li><strong>概率采样（重参数化技巧）</strong><br />为避免随机采样不可导，使用重参数化技巧生成隐变量 <spanclass="math inline">\(\mathbf{z}\)</span>：<br /><span class="math display">\[\mathbf{z} = \mu_\phi(\mathbf{x}) + \sigma_\phi(\mathbf{x}) \odot\epsilon, \quad \epsilon \sim \mathcal{N}(0, \mathbf{I})\]</span><ul><li><span class="math inline">\(\odot\)</span>：逐元素乘法<br /></li><li><spanclass="math inline">\(\epsilon\)</span>：从标准正态分布采样的噪声<br />&gt; <strong>意义</strong>：将随机性分离为可导运算，使梯度可回传。</li></ul></li></ol><h2 id="vae-的数学推导">3. VAE 的数学推导</h2><p>VAE将输入数据压缩到隐空间并建模高质量隐空间的过程，本质是通过<strong>概率编码器+ 隐变量分布约束 + 生成式重构</strong>的联合优化实现的。</p><h4id="隐空间的结构化kl散度的正则化作用"><strong>隐空间的结构化：KL散度的正则化作用</strong></h4><p>VAE 的核心创新是通过 <strong>KL散度约束</strong>使隐空间具备良好结构：</p><p>在 VAE 中，我们的目标是最大化边际似然 <spanclass="math inline">\(\log p_\theta(\mathbf{x})\)</span>，但由于 <spanclass="math inline">\(p_\theta(\mathbf{x}) = \intp_\theta(\mathbf{x},\mathbf{z})\,d\mathbf{z}\)</span> 难以直接计算，我们引入近似后验 <spanclass="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})\)</span> 并利用Jensen 不等式得到证据下界（ELBO）：</p><ol type="1"><li><p><strong>从对数似然到 ELBO</strong><br /><span class="math display">\[\log p_\theta(\mathbf{x})  = \log \int p_\theta(\mathbf{x},\mathbf{z})\,d\mathbf{z}  = \log \intq_\phi(\mathbf{z}|\mathbf{x})\frac{p_\theta(\mathbf{x},\mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})}\,d\mathbf{z}\]</span><br />应用 Jensen 不等式（<span class="math inline">\(\log\mathbb{E}[u]\ge\mathbb{E}[\log u]\)</span>）得到：<br /><span class="math display">\[\log p_\theta(\mathbf{x})  \ge \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})}\Bigl[\logp_\theta(\mathbf{x},\mathbf{z}) - \logq_\phi(\mathbf{z}|\mathbf{x})\Bigr]  \equiv \mathrm{ELBO}(\mathbf{x})\]</span></p></li><li><p><strong>ELBO 分解</strong><br /><span class="math display">\[\mathrm{ELBO}(\mathbf{x})  = \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})}[\logp_\theta(\mathbf{x}|\mathbf{z})]    - D_{\mathrm{KL}}\bigl(q_\phi(\mathbf{z}|\mathbf{x})\parallelp(\mathbf{z})\bigr)\]</span></p><ul><li>第一项：重构对数似然，衡量 <spanclass="math inline">\(\mathbf{z}\)</span> 重建 <spanclass="math inline">\(\mathbf{x}\)</span> 的能力。<br /></li><li>第二项：KL 散度，约束后验靠近先验 <spanclass="math inline">\(p(\mathbf{z})\)</span>（通常为 <spanclass="math inline">\(\mathcal{N}(0,I)\)</span>）。</li></ul></li><li><p><strong>重参数化技巧</strong><br />对于高斯后验 <spanclass="math inline">\(q_\phi(\mathbf{z}|\mathbf{x})=\mathcal{N}(\mathbf{z};\mu_\phi(\mathbf{x}),\sigma^2_\phi(\mathbf{x}))\)</span>，令<br /><span class="math display">\[\mathbf{z} = \mu_\phi(\mathbf{x}) +\sigma_\phi(\mathbf{x}) \odot \boldsymbol\epsilon,\quad  \boldsymbol\epsilon\sim\mathcal{N}(0,I)\]</span><br />将随机性隔离到 <spanclass="math inline">\(\boldsymbol\epsilon\)</span>，保证对 <spanclass="math inline">\((\mu,\sigma)\)</span>可导，从而可做反向传播。</p></li><li><p><strong>KL 散度的封闭解</strong><br />对两个 <span class="math inline">\(d\)</span> 维正态分布：<br /><spanclass="math display">\[D_{\mathrm{KL}}\bigl(\mathcal{N}(\mu,\sigma^2)\|\mathcal{N}(0,1)\bigr)  = \frac{1}{2}\sum_{i=1}^d\bigl(\mu_i^2 + \sigma_i^2 - \log\sigma_i^2 -1\bigr)\]</span></p></li><li><p><strong>最终优化目标</strong><br />最小化负 ELBO：<br /><span class="math display">\[\mathcal{L}_{\mathrm{VAE}}(\mathbf{x})  = -\mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})}[\logp_\theta(\mathbf{x}|\mathbf{z})]    + D_{\mathrm{KL}}\bigl(q_\phi(\mathbf{z}|\mathbf{x})\parallelp(\mathbf{z})\bigr)\]</span></p></li></ol><h4id="解码器从隐空间重建数据"><strong>解码器：从隐空间重建数据</strong></h4><p>解码器 $p_(|) $ 将隐变<spanclass="math inline">\((\mathbf{z}\)</span> 映射回数据空间： 1.<strong>生成过程</strong><br /><span class="math display">\[   \hat{\mathbf{x}} = \text{Decoder}_\theta(\mathbf{z})   \]</span> - 目标：最小化重建损失（如 MSE 或交叉熵）。</p><ol start="2" type="1"><li><strong>重建损失的双重角色</strong><ul><li>迫使 <span class="math inline">\(\mathbf{z}\)</span>保留足够信息以精确重建输入。<br /></li><li>与 KL 散度博弈：重构损失希望 <spanclass="math inline">\(\mathbf{z}\)</span> 包含更多信息，而 KL 散度希望<span class="math inline">\(\mathbf{z}\)</span>更接近简单先验分布。</li></ul></li></ol><h2 id="隐空间足够好的关键设计">4、隐空间“足够好”的关键设计</h2><h4 id="连续性continuity">1. <strong>连续性（Continuity）</strong></h4><ul><li><strong>机制</strong>：KL散度强制隐变量分布覆盖整个标准正态空间，而非孤立点簇。<br /></li><li><strong>效果</strong>：隐空间中相邻点解码后语义相似（如人脸隐空间中微笑程度连续变化）。</li></ul><h4 id="解耦性disentanglement">2.<strong>解耦性（Disentanglement）</strong></h4><ul><li><strong>机制</strong>：KL 散度隐式鼓励隐变量维度独立。显式方法如<span class="math inline">\(\beta\)</span>-VAE 进一步强化：<br /><span class="math display">\[\mathcal{L}_{\beta\text{-VAE}} = \mathbb{E}[\logp(\mathbf{x}|\mathbf{z})] - \beta D_{\text{KL}}(q(\mathbf{z}|\mathbf{x})\parallel p(\mathbf{z}))\]</span></li><li><strong>效果</strong>：单个隐变量维度控制单一语义特征（如发型、光照）。</li></ul><h4 id="鲁棒性robustness">3. <strong>鲁棒性（Robustness）</strong></h4><ul><li><strong>机制</strong>：概率采样使模型对输入噪声不敏感（方差 <spanclass="math inline">\(\sigma\)</span> 建模不确定性）。<br /></li><li><strong>效果</strong>：对遮挡或噪声数据仍能生成合理隐变量。</li></ul><p>VAE 通过<strong>概率编码器建模隐变量分布</strong>，并利用 <strong>KL散度约束</strong>将隐空间结构化，使其具备连续性、解耦性和鲁棒性。解码器的重建需求则确保隐变量保留足够信息。这种概率框架下的生成-推断平衡，使VAE的隐空间不仅是高效的数据压缩表示，更是可解释、可操控的语义空间，为自监督学习和生成任务奠定基础。</p><h2 id="一些参考资料">5. 一些参考资料</h2><p><ahref="https://zhuanlan.zhihu.com/p/348498294">机器学习方法—优雅的模型（一）：变分自编码器（VAE）</a></p><p><ahref="https://www.bilibili.com/video/BV1aE411o7qd/?p=170">机器学习-白板推导系列-变分自编码器</a></p><p><ahref="https://zhuanlan.zhihu.com/p/389295612">如何避免VAE后验坍塌?</a></p><p><ahref="https://spaces.ac.cn/archives/5253">科学空间-苏剑林-变分自编码器（一）：原来是这么一回事</a></p><p><ahref="https://spaces.ac.cn/archives/5343">科学空间-苏剑林-变分自编码器（二）：从贝叶斯观点出发</a></p><p><ahref="https://spaces.ac.cn/archives/5383">科学空间-苏剑林-变分自编码器（三）：这样做为什么能成？</a></p><p><ahref="https://spaces.ac.cn/archives/5887">科学空间-苏剑林-变分自编码器（四）：一步到位的聚类方案</a></p><p><ahref="https://spaces.ac.cn/archives/7381">科学空间-苏剑林-变分自编码器（五）：VAE+ BN = 更好的VAE</a></p>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明作者并非深度学习方面的专家如有错误欢迎讨论&quot;&gt;说明：作者并非深度学习方面的专家，如有错误欢迎讨论&lt;/h6&gt;</summary>
    
    
    
    
    <category term="AI" scheme="https://pd-ch.github.io/tags/AI/"/>
    
    <category term="math" scheme="https://pd-ch.github.io/tags/math/"/>
    
    <category term="unsupervised learning" scheme="https://pd-ch.github.io/tags/unsupervised-learning/"/>
    
    <category term="VAE" scheme="https://pd-ch.github.io/tags/VAE/"/>
    
  </entry>
  
  <entry>
    <title>人工智能基础</title>
    <link href="https://pd-ch.github.io/2025/03/09/The-way-to-Artificial-Intelligence.html"/>
    <id>https://pd-ch.github.io/2025/03/09/The-way-to-Artificial-Intelligence.html</id>
    <published>2025-03-09T00:00:00.000Z</published>
    <updated>2025-06-18T09:46:18.733Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明介绍目前的深度学习需要学习什么以及一些比较好的资源">说明：介绍目前的深度学习需要学习什么，以及一些比较好的资源。</h6><span id="more"></span><blockquote><h2 id="基础技术栈">基础技术栈</h2><ul><li><strong>系统</strong>：Debian<br /></li><li><strong>环境管理</strong>：venv，pip<br /></li><li><strong>编程语言</strong>：Python<br /></li><li><strong>AI 框架</strong>：Pytorch<br /></li><li><strong>内容管理工具</strong>：Git<br /></li><li><strong>集成开发环境</strong>：VScode（本地环境）、Jupyterlab（远程环境）</li></ul></blockquote><blockquote><h2 id="进阶技术栈">进阶技术栈</h2><ul><li><strong>编程语言</strong>：C++（g++、cling，标准=20）<br /></li><li><strong>AI 框架</strong>：Pytorch（AMP，DDP并发）<br /></li><li><strong>环境管理</strong>：Docker（开发容器与普通容器）<br /></li><li><strong>高性能计算</strong>：jax<br /></li><li><strong>大数据</strong>：duckdb（替代pandas）<br /></li><li><strong>构建工具</strong>：xmake</li></ul></blockquote><blockquote><h2 id="自选方向技术栈">自选方向技术栈</h2><ul><li><strong>数学建模</strong>：MATLAB / Mworks（Julia）<br /></li><li><strong>大数据</strong>：pyspark<br /></li><li><strong>科学计算</strong>：计算方法，Julia<br /></li><li><strong>云计算</strong>：K8s（rancher）、KVM、SDS（ceph）、SDN<br /></li><li><strong>边缘智能</strong>：Tensort、onnx<br /></li><li><strong>高性能AI</strong>：flax、optax、orbax</li><li><strong>加速器</strong>：FPGA（xilinx）、vitis、PCIe</li></ul></blockquote><blockquote><p><strong>注：</strong><br />1. 基础技术栈建议在进入方向后3-6个月内完成；<br />2. 进阶技术栈建议在基础学习完后1-2个月内完成；<br />3. 自选方向技术栈仅作为参考，目前阶段无强制要求；<br />4. 使用“/”连接表示可选择其中一种技术，使用“，”仅作为分隔符；<br />5. WSL2不再推荐，仅作为过渡使用。</p></blockquote><hr /><h3 id="以下推荐一些需要的数学知识">以下推荐一些需要的数学知识</h3><ul><li><strong><ahref="https://www.zhihu.com/column/gs-linear-algebra">线性代数</a></strong>：介绍了人工智能所需的线性代数基础</li><li><strong><ahref="https://www.zhihu.com/column/c_1334301979816820736">机器学习方法</a></strong>：深入介绍机器学习中的一些基础方法</li></ul>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明介绍目前的深度学习需要学习什么以及一些比较好的资源&quot;&gt;说明：介绍目前的深度学习需要学习什么，以及一些比较好的资源。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="AI" scheme="https://pd-ch.github.io/tags/AI/"/>
    
    <category term="math" scheme="https://pd-ch.github.io/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>简单介绍一下我本人的环境搭建</title>
    <link href="https://pd-ch.github.io/2024/09/29/My-environment-setup.html"/>
    <id>https://pd-ch.github.io/2024/09/29/My-environment-setup.html</id>
    <published>2024-09-29T00:00:00.000Z</published>
    <updated>2025-06-18T09:46:18.733Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明仅介绍本人主要使用的配置留档以便后来可快速配置">说明：仅介绍本人主要使用的配置，留档以便后来可快速配置。</h6><span id="more"></span><h3 id="目录">目录</h3><ul><li><a href="#step-0-系统启动盘制作">Step 0. 系统启动盘制作</a></li><li><a href="#step-1-终端美化与代理设置">Step 1.终端美化与代理设置</a></li><li><a href="#step-2-安装NVIDIA驱动">Step 2. 安装NVIDIA驱动</a></li><li><a href="#step-3-安装python环境管理工具">Step 3.安装python环境管理工具</a></li></ul><h2 id="step-0.-系统启动盘制作">Step 0. 系统启动盘制作</h2><p>简单来说，Ventoy是一个制作可启动U盘的开源工具。有了Ventoy你就无需反复地格式化U盘，你只需要把ISO/WIM/IMG/VHD(x)/EFI等类型的文件直接拷贝到U盘里面就可以启动了，无需其他操作。你可以一次性拷贝很多个不同类型的镜像文件，Ventoy会在启动时显示一个菜单来供你进行选择。 下载地址:<ahref="https://www.ventoy.net/cn/download.html"class="uri">https://www.ventoy.net/cn/download.html</a>安装到U盘以后，只需要将iso镜像复制到U盘中即可。个人建议前往镜像站下载操作系统的iso镜像。</p><p>安装过程因人而异，故此不再赘述。个人比较喜欢Debian，在安装进行到分区这一步时，建议删除除引导分区以外的其它分区，我们不需要swap，以及这样做方便我们创建Btrfs主分区，将它的挂载点设置在“/”下。完成安装。(建议使用DVD镜像，避免安装时过多的等待)</p><p>接着进入系统，切换为root用户，为自己创建的用户添加sudo权限，并进行换源。此处不再赘述。值得一提的是，换源不再建议使用tuna(清华)源(用的人太多了，容易断流)。</p><p>至此，我们的系统就初步配置好了。</p><h2 id="step-1.-终端美化与代理设置">Step 1. 终端美化与代理设置</h2><p>终端个人推荐使用zsh，主题使用powerlevel10k，插件仅需zsh-autosuggestions与zsh-syntax-highlighting即可。配置可参照:<a href="https://www.haoyep.com/posts/zsh-config-oh-my-zsh/"class="uri">https://www.haoyep.com/posts/zsh-config-oh-my-zsh/</a></p><p>代理的设置建议如下 新建<strong>~/scripts/proxy.sh</strong>,并在该脚本文件中复制以下代码,其中hostip和port按需更改:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br>hostip=127.0.0.1<br>port=7890<br><br>PROXY_HTTP=<span class="hljs-string">&quot;http://<span class="hljs-variable">$&#123;hostip&#125;</span>:<span class="hljs-variable">$&#123;port&#125;</span>&quot;</span><br><br><span class="hljs-function"><span class="hljs-title">set_proxy</span></span>()&#123;<br>  <span class="hljs-built_in">export</span> http_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> HTTP_PROXY=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br><br>  <span class="hljs-built_in">export</span> https_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> HTTPS_proxy=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span>&quot;</span><br><br>  <span class="hljs-built_in">export</span> ALL_PROXY=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PROXY_SOCKS5&#125;</span>&quot;</span><br>  <span class="hljs-built_in">export</span> all_proxy=<span class="hljs-variable">$&#123;PROXY_SOCKS5&#125;</span><br><br>  git config --global http.https://github.com.proxy <span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span><br>  git config --global https.https://github.com.proxy <span class="hljs-variable">$&#123;PROXY_HTTP&#125;</span><br><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy has been opened.&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">unset_proxy</span></span>()&#123;<br>  <span class="hljs-built_in">unset</span> http_proxy<br>  <span class="hljs-built_in">unset</span> HTTP_PROXY<br>  <span class="hljs-built_in">unset</span> https_proxy<br>  <span class="hljs-built_in">unset</span> HTTPS_PROXY<br>  <span class="hljs-built_in">unset</span> ALL_PROXY<br>  <span class="hljs-built_in">unset</span> all_proxy<br>  git config --global --<span class="hljs-built_in">unset</span> http.https://github.com.proxy<br>  git config --global --<span class="hljs-built_in">unset</span> https.https://github.com.proxy<br><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy has been closed.&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">test_setting</span></span>()&#123;<br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Host IP:&quot;</span> <span class="hljs-variable">$&#123;hostip&#125;</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Try to connect to Google...&quot;</span><br>  resp=$(curl -I -s --connect-timeout 5 -m 5 -w <span class="hljs-string">&quot;%&#123;http_code&#125;&quot;</span> -o /dev/null www.google.com)<br>  <span class="hljs-keyword">if</span> [ <span class="hljs-variable">$&#123;resp&#125;</span> = 200 ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy setup succeeded!&quot;</span><br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Proxy setup failed!&quot;</span><br>  <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;set&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  set_proxy<br><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;unset&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  unset_proxy<br><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;test&quot;</span> ]<br><span class="hljs-keyword">then</span><br>  test_setting<br><span class="hljs-keyword">else</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Unsupported arguments.&quot;</span><br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure> 在你的.zshrc或者.bashrc中添加<strong>alias proxy=“source~/scripts/proxy.sh”</strong></p><p>使用时只需要在终端输入proxy set;proxy unset;proxy test.</p><p>至此,终端美化与代理设置就初步完成了</p><h2 id="step-2.-安装nvidia驱动">Step 2. 安装NVIDIA驱动</h2><p>你完全可以<strong>sudo apt installnvidia-driver</strong>来安装开源驱动但是我更推荐安装闭源驱动，如果有内核更新，记得要<strong>sudo apt installlinux-headers-$(uname -r)</strong>.</p><p>安装 apt GPG keyring 包，目的是获取 GPG 密钥 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://developer.download.nvidia.com/compute/cuda/repos/debian12/x86_64/cuda-keyring_1.1-1_all.deb<br><span class="hljs-built_in">sudo</span> dpkg -i cuda-keyring_1.1-1_all.deb<br></code></pre></td></tr></table></figure></p><p>可以到此位置<ahref="https://developer.download.nvidia.com/compute/cuda/repos/"class="uri">https://developer.download.nvidia.com/compute/cuda/repos/</a>浏览具体发行版</p><p>apt 安装驱动 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt update<br><span class="hljs-built_in">sudo</span> apt -y install nvidia-driver cuda-drivers<br></code></pre></td></tr></table></figure></p><p>或者 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt install nvidia-driver-assistant<br>nvidia-driver-assistant<br></code></pre></td></tr></table></figure> 此时会给出像下面的指引 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">Detected GPUs:<br>  NVIDIA GeForce RTX 4060 Laptop GPU - (pci_id 0x28E0)<br><br>Detected system:<br>  Debian GNU/Linux 13<br><br>Please copy and <span class="hljs-built_in">paste</span> the following <span class="hljs-built_in">command</span> to install the open kernel module flavour:<br>  <span class="hljs-built_in">sudo</span> apt-get install -Vy nvidia-open<br></code></pre></td></tr></table></figure> 按照指引<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install -Vy nvidia-open<br></code></pre></td></tr></table></figure> 即可</p><p>至此,你已经几乎完成了环境的搭建。</p><h2 id="step-3.-安装python环境管理工具">Step 3.安装python环境管理工具</h2><p>这个看个人品味,我推荐使用miniconda,venv或者mamba.镜像站使用tuna或者bfsu.在此笔者假设读者熟悉上面三种的任意一种创建完虚拟的环境后,进入虚拟环境对pip进行换源.直接运行 <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> torch<br></code></pre></td></tr></table></figure>如果在安装完torch后安装了大量nvidia*的包,那么就可以放心了,你安装的是pytorchwith GPU</p><h5id="你已经完成了深度学习环境搭建立刻开始愉快的学习吧">你已经完成了深度学习环境搭建,立刻开始愉快的学习吧！</h5>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明仅介绍本人主要使用的配置留档以便后来可快速配置&quot;&gt;说明：仅介绍本人主要使用的配置，留档以便后来可快速配置。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="env setup" scheme="https://pd-ch.github.io/tags/env-setup/"/>
    
  </entry>
  
  <entry>
    <title>Intel A770 GPU深度学习环境搭建（Linux）</title>
    <link href="https://pd-ch.github.io/2024/06/28/A770_deeplearning_env_setup.html"/>
    <id>https://pd-ch.github.io/2024/06/28/A770_deeplearning_env_setup.html</id>
    <published>2024-06-28T00:00:00.000Z</published>
    <updated>2025-06-18T09:46:18.733Z</updated>
    
    <content type="html"><![CDATA[<h6id="说明windows下也可以进行环境搭建但是个人更偏爱debian">说明：Windows下也可以进行环境搭建，但是个人更偏爱Debian。</h6><span id="more"></span><h6id="updatepytorch在24年10月中旬发布了2.5版本添加了intel-gpu支持使用以下代码以启用."><strong>Update:pytorch在24年10月中旬发布了2.5版本,添加了IntelGPU支持,使用以下代码以启用.</strong></h6><p>这是pytorch官方的链接<ahref="https://pytorch.org/docs/main/notes/get_start_xpu.html"class="uri">https://pytorch.org/docs/main/notes/get_start_xpu.html</a></p><p>我们仅仅需要准备好GPU驱动即可。 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">pip3 install torch torchvision torchaudio --index-url https:<span class="hljs-regexp">//</span>download.pytorch.org<span class="hljs-regexp">/whl/</span>test/xpu<br></code></pre></td></tr></table></figure></p><h6id="以下外国博客也可参考我仍然只推荐使用torch2.5preview"><strong>以下外国博客也可参考,我仍然只推荐使用torch2.5preview</strong></h6><p><ahref="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/"class="uri">https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/</a></p><h3 id="目录">目录</h3><ul><li><a href="#step-0-准备工作">Step 0. 准备工作</a></li><li><a href="#step-1-安装GPU驱动">Step 1. 安装GPU驱动</a></li><li><a href="#step-2-安装Intel®-oneAPI-Base-Toolkit">Step 2.安装Intel®-oneAPI-Base-Toolkit</a></li><li><a href="#step-3-安装Intel®-Extension-for-PyTorch">Step 3.安装Intel®-Extension-forPyTorch</a></li><li><a href="#step-4-安装xpu-smi">Step 4. 安装xpu-smi</a></li></ul><h2 id="step-0-准备工作">Step 0 准备工作</h2><p>首先你需要有一台使用Intel GPU的电脑，本文针对Intel ArcA770（16GB）编写，系统环境为Debian sid。</p><p>关于Intel® Extension for PyTorch的安装可以参考官方示例<ahref="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.1.30%2bxpu&amp;os=linux%2fwsl2&amp;package=pip"class="uri">https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.1.30%2bxpu&amp;os=linux%2fwsl2&amp;package=pip</a>。以下部分是我自己踩的一点坑。</p><h2 id="step-1-安装gpu驱动">step 1 安装GPU驱动</h2><p>前往<ahref="https://dgpu-docs.intel.com/driver/client/overview.html">IntelGPU驱动网站</a>，进行其中的3.1.1-3.1.5部分。树外内核部分无需理会。</p><h2 id="step-2-安装intel-oneapi-base-toolkit">step 2安装Intel®-oneAPI-Base-Toolkit</h2><p>前往<ahref="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html?operatingsystem=linux&amp;linux-install-type=apt">Intel®-oneAPI-Base-Toolkit</a>网站，使用apt进行安装。</p><h2 id="step-3-安装intel-extension-forpytorch">step 3安装Intel®-Extension-forPyTorch</h2><p>我选择的是使用pip进行安装。你可以先使用conda创建一个虚拟环境，python版本推荐3.11。安装命令 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">python</span> -m pip install torch==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.post2 torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span>.post2 torchaudio==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.post2 intel-extension-for-pytorch==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">30</span>.post0 oneccl_bind_pt==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">300</span>+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/<br></code></pre></td></tr></table></figure></p><p>完成后进行测试。</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">source</span> <span class="hljs-regexp">/opt/i</span>ntel<span class="hljs-regexp">/oneapi/</span>setvars.sh<br></code></pre></td></tr></table></figure><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss">python -c &quot;import torch; import intel_extension_for_pytorch as ipex; <span class="hljs-built_in">print</span>(torch.__version__); <span class="hljs-built_in">print</span>(ipex.__version__); <span class="hljs-selector-attr">[print(f<span class="hljs-string">&#x27;[&#123;i&#125;]: &#123;torch.xpu.get_device_properties(i)&#125;&#x27;</span>) for i in range(torch.xpu.device_count())]</span>;&quot;<br></code></pre></td></tr></table></figure><p>最后成功识别到显卡即为安装成功。</p><p>前往<ahref="https://intel.github.io/intel-extension-for-pytorch/xpu/2.1.30+xpu/tutorials/examples.html">example</a>进行愉快的玩耍吧。</p><h1 id="step-4-安装xpu-smi">step 4 安装xpu-smi</h1><p>最后一部分我也还在摸索。使用这个软件也是因为intel-gpu-tools查看不了显存使用情况。</p><p>前往<ahref="https://github.com/intel/xpumanager/releases/tag/V1.2.37">release</a>页面下载安装即可。</p><p>使用说明在GitHub仓库的readme中。</p>]]></content>
    
    
    <summary type="html">&lt;h6
id=&quot;说明windows下也可以进行环境搭建但是个人更偏爱debian&quot;&gt;说明：Windows下也可以进行环境搭建，但是个人更偏爱Debian。&lt;/h6&gt;</summary>
    
    
    
    
    <category term="env setup" scheme="https://pd-ch.github.io/tags/env-setup/"/>
    
    <category term="intel GPU" scheme="https://pd-ch.github.io/tags/intel-GPU/"/>
    
  </entry>
  
</feed>
